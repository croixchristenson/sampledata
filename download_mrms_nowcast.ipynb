{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "258cfa16-f76f-452f-97f7-5083ee21343c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pysteps configuration file found at: C:\\Users\\16126\\pysteps\\pystepsrc\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import gzip\n",
    "import shutil\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature\n",
    "import cartopy\n",
    "from metpy.plots import USCOUNTIES\n",
    "from datetime import datetime, timedelta\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from pysteps import io, nowcasts, rcparams\n",
    "from pysteps.motion.lucaskanade import dense_lucaskanade\n",
    "from pysteps.postprocessing.ensemblestats import excprob\n",
    "from pysteps.utils import conversion, dimension, transformation\n",
    "from pysteps.visualization import plot_precip_field\n",
    "import matplotlib.colors as colors\n",
    "import re\n",
    "import pandas as pd\n",
    "# import scikit-image\n",
    "\n",
    "# Set nowcast parameters\n",
    "n_ens_members = 20 #20\n",
    "n_leadtimes = 7\n",
    "seed = 20 #24\n",
    "precip_thr = -10\n",
    "\n",
    "#north plains\n",
    "domain_name = 'north_plains_'\n",
    "domain_lat = [40, 49]\n",
    "domain_lon = [-110, -95]\n",
    "\n",
    "#co\n",
    "domain_name = 'co_'\n",
    "domain_lat = [36.7, 41.5]\n",
    "domain_lon = [-110, -101]\n",
    "\n",
    "# #neb\n",
    "# domain_name = 'neb_'\n",
    "# domain_lat = [39, 45]\n",
    "# domain_lon = [-106, -95]\n",
    "\n",
    "# #US\n",
    "# domain_name = 'us_'\n",
    "# domain_lat = [29, 48]\n",
    "# domain_lon = [-124, -67]\n",
    "\n",
    "# #Midwest\n",
    "# domain_name = 'Midwest_'\n",
    "# domain_lat = [42, 48]\n",
    "# domain_lon = [-96, -83]\n",
    "\n",
    "# #custom\n",
    "# domain_name = 'custom_'\n",
    "# domain_lat = [33, 40]\n",
    "# domain_lon = [-103, -90]\n",
    "\n",
    "# # NW\n",
    "# domain_name = 'nw_'\n",
    "# domain_lat = [41, 49]\n",
    "# domain_lon = [-124, -110]\n",
    "\n",
    "# num_prev_files \n",
    "# n_ens_members \n",
    "# n_leadtimes \n",
    "# seed \n",
    "# execution_time\n",
    "# method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "610009e3-cdd6-4920-b01d-2117b676d907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Available datasets:\n",
      "\n",
      "Case     Event date             Source                                       \n",
      "\n",
      "fmi      2016-09-28 14:45 UTC   Finish Meteorological Institute              \n",
      "fmi2     2017-05-09 10:45 UTC   Finish Meteorological Institute              \n",
      "mch      2015-05-15 15:45 UTC   MeteoSwiss                                   \n",
      "mch2     2016-07-11 20:45 UTC   MeteoSwiss                                   \n",
      "mch3     2017-01-31 09:45 UTC   MeteoSwiss                                   \n",
      "opera    2018-08-24 18:00 UTC   OPERA                                        \n",
      "knmi     2010-08-26 00:00 UTC   Royal Netherlands Meteorological Institute   \n",
      "bom      2018-06-16 10:00 UTC   Australian Bureau of Meteorology             \n",
      "mrms     2019-06-10 00:00 UTC   NSSL's Multi-Radar/Multi-Sensor System       \n",
      "mrms_os  2023-05-07 23:00 UTC   NSSL's Multi-Radar/Multi-Sensor System       \n",
      "{'fn_ext': 'grib2',\n",
      " 'fn_pattern': 'MRMS_PrecipRate_00.00_%Y%m%d-%H%M%S',\n",
      " 'importer': 'mrms_grib',\n",
      " 'importer_kwargs': {},\n",
      " 'path_fmt': '%Y\\\\%m\\\\%d',\n",
      " 'root_path': 'C:\\\\Users\\\\16126\\\\pysteps_data\\\\mrms_os',\n",
      " 'timestep': 8}\n"
     ]
    }
   ],
   "source": [
    "from pysteps import datasets\n",
    "# from pysteps import io, conversion, dimension, transformation\n",
    "import pysteps\n",
    "\n",
    "datasets.info()\n",
    "from pprint import pprint\n",
    "import pysteps\n",
    "pprint(pysteps.rcparams.data_sources[\"mrms_os\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a04bdf-42fe-4c67-a0f7-de0c694e5d26",
   "metadata": {},
   "source": [
    "## Download and process real-time MRMS Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8404253-6f9e-413f-81b6-7496ffd3ce65",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://mrms.ncep.noaa.gov/data/2D/PrecipRate/'\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Find all the links on the page\n",
    "links = soup.find_all('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "570d57ca-1edd-4b74-810c-724c7520d1fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MRMS_PrecipRate_00.00_20230520-143000.grib2.gz', 'MRMS_PrecipRate_00.00_20230520-142200.grib2.gz', 'MRMS_PrecipRate_00.00_20230520-141400.grib2.gz', 'MRMS_PrecipRate_00.00_20230520-140600.grib2.gz', 'MRMS_PrecipRate_00.00_20230520-135800.grib2.gz']\n"
     ]
    }
   ],
   "source": [
    "# Filter the links to get the .gz files and select every 3rd file\n",
    "gz_files = [link['href'] for link in links if link['href'].endswith('.gz')]\n",
    "gz_files.sort(reverse=True)\n",
    "selected_files = gz_files[::4][:5]\n",
    "print(selected_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32b15c80-f952-45aa-93ff-1680d7c1f8f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exists: C:\\Users\\16126\\pysteps_data\\mrms_os\\2023\\05\\20\n",
      "Downloaded: MRMS_PrecipRate_00.00_20230520-143000.grib2.gz\n",
      "Downloaded: MRMS_PrecipRate_00.00_20230520-142200.grib2.gz\n",
      "Downloaded: MRMS_PrecipRate_00.00_20230520-141400.grib2.gz\n",
      "Downloaded: MRMS_PrecipRate_00.00_20230520-140600.grib2.gz\n",
      "Downloaded: MRMS_PrecipRate_00.00_20230520-135800.grib2.gz\n"
     ]
    }
   ],
   "source": [
    "# from datetime import datetime\n",
    "# import os\n",
    "# Get the current date\n",
    "current_date = datetime.now().date()\n",
    "\n",
    "# Extract the current year, month, and day\n",
    "current_year = str(current_date.year)\n",
    "current_month = f\"{current_date.month:02d}\"\n",
    "current_day = f\"{current_date.day:02d}\"\n",
    "\n",
    "# Download the selected files\n",
    "download_folder = os.path.join(r'C:\\Users\\16126\\pysteps_data\\mrms_os', current_year, current_month, current_day)\n",
    "\n",
    "# Check if the path exists\n",
    "if not os.path.exists(download_folder):\n",
    "    # Create the directory\n",
    "    os.makedirs(download_folder)\n",
    "    print(\"Directory created:\", download_folder)\n",
    "else:\n",
    "    print(\"Directory already exists:\", download_folder)\n",
    "\n",
    "# Get a list of all files in the folder\n",
    "files = os.listdir(download_folder)\n",
    "\n",
    "# Remove each file in the folder\n",
    "for file in files:\n",
    "    file_path = os.path.join(download_folder, file)\n",
    "    os.remove(file_path)\n",
    "    \n",
    "for file in selected_files:\n",
    "    file_url = url + file\n",
    "    response = requests.get(file_url)\n",
    "    \n",
    "    # Create the file path in the download folder\n",
    "    file_path = os.path.join(download_folder, file)\n",
    "    \n",
    "    # Save the file to the specified folder location\n",
    "    with open(file_path, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "        print(f\"Downloaded: {file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0ab2bcb-6678-47f5-80bf-a6d49d987b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted: MRMS_PrecipRate_00.00_20230520-135800.grib2.gz -> MRMS_PrecipRate_00.00_20230520-135800.grib2\n",
      "Removed: MRMS_PrecipRate_00.00_20230520-135800.grib2.gz\n",
      "Converted: MRMS_PrecipRate_00.00_20230520-140600.grib2.gz -> MRMS_PrecipRate_00.00_20230520-140600.grib2\n",
      "Removed: MRMS_PrecipRate_00.00_20230520-140600.grib2.gz\n",
      "Converted: MRMS_PrecipRate_00.00_20230520-141400.grib2.gz -> MRMS_PrecipRate_00.00_20230520-141400.grib2\n",
      "Removed: MRMS_PrecipRate_00.00_20230520-141400.grib2.gz\n",
      "Converted: MRMS_PrecipRate_00.00_20230520-142200.grib2.gz -> MRMS_PrecipRate_00.00_20230520-142200.grib2\n",
      "Removed: MRMS_PrecipRate_00.00_20230520-142200.grib2.gz\n",
      "Converted: MRMS_PrecipRate_00.00_20230520-143000.grib2.gz -> MRMS_PrecipRate_00.00_20230520-143000.grib2\n",
      "Removed: MRMS_PrecipRate_00.00_20230520-143000.grib2.gz\n"
     ]
    }
   ],
   "source": [
    "input_directory = download_folder\n",
    "output_directory = download_folder\n",
    "\n",
    "# Get a list of all files in the input directory\n",
    "files = os.listdir(input_directory)\n",
    "\n",
    "# Filter the list to include only the .gz files\n",
    "gz_files = [file for file in files if file.endswith('.gz')]\n",
    "\n",
    "# Iterate over the .gz files and convert them to .grib2\n",
    "for gz_file in gz_files:\n",
    "    gz_path = os.path.join(input_directory, gz_file)\n",
    "    grib2_file = os.path.splitext(gz_file)[0]\n",
    "    grib2_path = os.path.join(output_directory, grib2_file)\n",
    "    \n",
    "    with gzip.open(gz_path, 'rb') as f_in:\n",
    "        with open(grib2_path, 'wb') as f_out:\n",
    "            shutil.copyfileobj(f_in, f_out)\n",
    "    \n",
    "    print(f\"Converted: {gz_file} -> {grib2_file}\")\n",
    "    # Remove the .gz file\n",
    "    os.remove(gz_path)\n",
    "    print(f\"Removed: {gz_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0df5cc5f-f3ba-4da4-8dc6-03c8092ec286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRMS_PrecipRate_00.00_20230520-143000.grib2 20230520-143000\n"
     ]
    }
   ],
   "source": [
    "# Get a list of all files in the input directory\n",
    "files = os.listdir(input_directory)\n",
    "files_sorted = sorted(files, reverse=True)\n",
    "gif_date_start = re.search(r\"(\\d{8}-\\d{6})\", files_sorted[0]).group()\n",
    "# gif_date_start = gif_date_start.split('_')\n",
    "# gif_date_start = gif_date_start[-1].split('.')[0]\n",
    "print(files_sorted[0],gif_date_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5eccb7a9-b547-4eb2-bec4-17324885b840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatted datetime: 202305201430\n"
     ]
    }
   ],
   "source": [
    "# Example filename\n",
    "filename = files_sorted[0]\n",
    "\n",
    "# Example filename\n",
    "filename = files_sorted[0]\n",
    "\n",
    "# Extract year, month, day, hour, and minute from the filename\n",
    "year = filename[22:26]\n",
    "month = filename[26:28]\n",
    "day = filename[28:30]\n",
    "hour = filename[31:33]\n",
    "minute = filename[33:35]\n",
    "\n",
    "# Format the extracted values\n",
    "formatted_datetime = f\"{year}{month}{day}{hour}{minute}\"\n",
    "\n",
    "# Print the formatted datetime\n",
    "print(\"Formatted datetime:\", formatted_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "debc4097-a2b6-4e77-b73a-7666c688f1ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New date: 202305201422\n"
     ]
    }
   ],
   "source": [
    "date = datetime.strptime(formatted_datetime, \"%Y%m%d%H%M\")\n",
    "\n",
    "# Subtract 8 minutes from the datetime object\n",
    "new_date = date - timedelta(minutes=8)\n",
    "\n",
    "# Format the new date as a string\n",
    "new_date_string = new_date.strftime(\"%Y%m%d%H%M\")\n",
    "\n",
    "# Print the new date string\n",
    "print(\"New date:\", new_date_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2140531d-2e5d-484e-b050-1539a9326795",
   "metadata": {},
   "source": [
    "## Ingest and Map MRMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d508f4ae-39f9-4498-89be-45297377dc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# date = datetime.strptime(formatted_datetime, \"%Y%m%d%H%M\")\n",
    "date = datetime.strptime(\"202305181432\", \"%Y%m%d%H%M\")\n",
    "\n",
    "data_source = \"mrms_os\"      \n",
    "from pysteps.visualization.basemaps import plot_map_cartopy\n",
    "\n",
    "# Load data source config\n",
    "# data_source = \"mrms_os\"\n",
    "root_path = rcparams.data_sources[data_source][\"root_path\"]\n",
    "path_fmt = rcparams.data_sources[data_source][\"path_fmt\"]\n",
    "fn_pattern = rcparams.data_sources[data_source][\"fn_pattern\"]\n",
    "fn_ext = rcparams.data_sources[data_source][\"fn_ext\"]\n",
    "importer_name = rcparams.data_sources[data_source][\"importer\"]\n",
    "importer_kwargs = rcparams.data_sources[data_source][\"importer_kwargs\"]\n",
    "timestep = rcparams.data_sources[data_source][\"timestep\"]\n",
    "num_prev_files = 4\n",
    "\n",
    "# Find the radar files in the archive\n",
    "fns = io.find_by_date(\n",
    "    date, root_path, path_fmt, fn_pattern, fn_ext, timestep, num_prev_files\n",
    ")\n",
    "\n",
    "# Read the data from the archive\n",
    "importer = io.get_method(importer_name, \"importer\")\n",
    "R, _, metadata = io.read_timeseries(fns, importer, **importer_kwargs)\n",
    "\n",
    "# Convert to rain rate\n",
    "# R, metadata = conversion.to_rainrate(R, metadata)\n",
    "\n",
    "# Upscale data to 2 km to limit memory usage\n",
    "# R, metadata = dimension.aggregate_fields_space(R, metadata, 2000)\n",
    "    \n",
    "for i in range(R.shape[0]):\n",
    "    if i == 0:\n",
    "        f_step = 32\n",
    "    elif i == 1:\n",
    "        f_step = 24\n",
    "    elif i == 2:\n",
    "        f_step = 16\n",
    "    elif i == 3:\n",
    "        f_step = 8\n",
    "    elif i == 4:\n",
    "        f_step = 0\n",
    "\n",
    "    # Subtract 8 minutes from the datetime object\n",
    "    new_date = date - timedelta(minutes=(num_prev_files - i) * 8)\n",
    "    # Format the new date as a string\n",
    "    new_date_string = new_date.strftime(\"%Y%m%d%H%M\")\n",
    "    \n",
    "    # Get the extent values from metadata\n",
    "    x1 = metadata['x1']\n",
    "    x2 = metadata['x2']\n",
    "    y2 = metadata['y1']\n",
    "    y1 = metadata['y2']\n",
    "\n",
    "    # Create a grid of x and y coordinates\n",
    "    x = np.linspace(x1, x2, R.shape[2])\n",
    "    y = np.linspace(y1, y2, R.shape[1])\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "\n",
    "    bounds = [0.08, 0.16, 0.25,  0.40, 0.63, 1, 1.6, 2.5, 4, 6.3, 10, 16, 25, 40, 63, 100, 160, 220]\n",
    "    norm = colors.BoundaryNorm(boundaries=bounds, ncolors=len(bounds))\n",
    "    colormap = colors.ListedColormap(['#9e7c94', #grey\n",
    "                                      '#650064','#ae00b0','#dc01da', #purples 5-15\n",
    "                                      '#3531c3','#0b60f9', #blues\n",
    "                                      '#009697', '#00c930','#65ff01','#98ff00','#c6fe00', #greens\n",
    "                                      '#fffd04', #yellow\n",
    "                                      '#ffc802', '#ffa000','#ff7d01', #orange\n",
    "                                      '#df1a01','#8d0000' ]) #red           #65-75\n",
    "\n",
    "    # Create the figure and subplots\n",
    "    # fig, axs = plt.subplots(1, 2, figsize=(18, 9), dpi=200, subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(12, 12), dpi=200, subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "\n",
    "    # Add features to both subplots\n",
    "    for ax in axs:\n",
    "        ax.add_feature(USCOUNTIES.with_scale('5m'), linewidth=.5, edgecolor='darkgrey')\n",
    "        ax.add_feature(cartopy.feature.STATES, linewidth=1, edgecolor='black')\n",
    "        \n",
    "        # Add features to both subplots\n",
    "        # Set up the first subplot\n",
    "        axs[0].set_title(new_date_string + \" MRMS (-%i min)\" % (f_step))\n",
    "        axs[0].set_xlim(domain_lon)\n",
    "        axs[0].set_ylim(domain_lat)\n",
    "\n",
    "        # Set up the second subplot\n",
    "        axs[1].set_title(new_date_string + \" MRMS (-%i min)\" % (f_step))\n",
    "        axs[1].set_xlim(domain_lon)\n",
    "        axs[1].set_ylim(domain_lat)\n",
    "\n",
    "        # Plot in the first subplot\n",
    "        axs[0].contourf(X, Y, R[i, :, :], levels=bounds, norm=norm, cmap=colormap)\n",
    "\n",
    "        # Plot in the second subplot\n",
    "        axs[1].contourf(X, Y, R[i, :, :], levels=bounds, norm=norm, cmap=colormap)\n",
    "        \n",
    "        # Plot 2.5mm contour\n",
    "        axs[0].contour(X, Y, R[i, :, :], levels=[.254], colors='black')\n",
    "        axs[1].contour(X, Y, R[i, :, :], levels=[.254], colors='black')\n",
    "\n",
    "    # Save the figure\n",
    "    file_name = str(i) + \"_MRMS (-%i min)\" % (f_step)\n",
    "    mrms_radar_path = os.path.join(r'G:\\My Drive\\PowPow\\Resort Graphs\\forecast_radar\\mrms', file_name)\n",
    "    plt.savefig(mrms_radar_path + '.png', dpi=200, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    \n",
    "# Log-transform the data to unit of dBR, set the threshold to 0.1 mm/h,\n",
    "# set the fill value to -15 dBR\n",
    "# R, metadata = transformation.dB_transform(R, metadata, threshold=0.1, zerovalue=-15.0)\n",
    "\n",
    "# Set missing values with the fill value\n",
    "R[~np.isfinite(R)] = -15.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538059b9-d86c-466f-9c2c-09bfd255ddb8",
   "metadata": {},
   "source": [
    "## Create S-PROG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf046c92-f398-44b3-84ee-5f0231c2eb1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing S-PROG nowcast\n",
      "------------------------\n",
      "\n",
      "Inputs\n",
      "------\n",
      "input dimensions: 875x1750\n",
      "\n",
      "Methods\n",
      "-------\n",
      "extrapolation:          semilagrangian\n",
      "bandpass filter:        gaussian\n",
      "decomposition:          fft\n",
      "conditional statistics: no\n",
      "probability matching:   cdf\n",
      "FFT method:             numpy\n",
      "domain:                 spatial\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "number of time steps:     7\n",
      "parallel threads:         1\n",
      "number of cascade levels: 6\n",
      "order of the AR(p) model: 2\n",
      "precip. intensity threshold: -10\n",
      "************************************************\n",
      "* Correlation coefficients for cascade levels: *\n",
      "************************************************\n",
      "-----------------------------------------\n",
      "| Level |     Lag-1     |     Lag-2     |\n",
      "-----------------------------------------\n",
      "| 1     | 0.999996      | 0.998849      |\n",
      "-----------------------------------------\n",
      "| 2     | 0.999951      | 0.972260      |\n",
      "-----------------------------------------\n",
      "| 3     | 0.999522      | 0.962960      |\n",
      "-----------------------------------------\n",
      "| 4     | 0.995214      | 0.950906      |\n",
      "-----------------------------------------\n",
      "| 5     | 0.956384      | 0.833081      |\n",
      "-----------------------------------------\n",
      "| 6     | 0.809354      | 0.593276      |\n",
      "-----------------------------------------\n",
      "****************************************\n",
      "* AR(p) parameters for cascade levels: *\n",
      "****************************************\n",
      "------------------------------------------------------\n",
      "| Level |    Phi-1     |    Phi-2     |    Phi-0     |\n",
      "------------------------------------------------------\n",
      "| 1     | 1.994561     | -0.994568    | 0.000283     |\n",
      "------------------------------------------------------\n",
      "| 2     | 1.980259     | -0.980356    | 0.001956     |\n",
      "------------------------------------------------------\n",
      "| 3     | 1.939087     | -0.940014    | 0.010548     |\n",
      "------------------------------------------------------\n",
      "| 4     | 1.813241     | -0.821961    | 0.055655     |\n",
      "------------------------------------------------------\n",
      "| 5     | 1.480344     | -0.547855    | 0.244372     |\n",
      "------------------------------------------------------\n",
      "| 6     | 0.954305     | -0.179094    | 0.577825     |\n",
      "------------------------------------------------------\n",
      "Starting nowcast computation.\n",
      "Computing nowcast for time step 1... done.\n",
      "Computing nowcast for time step 2... "
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "# Estimate the motion field\n",
    "from pysteps import motion\n",
    "V = dense_lucaskanade(R)\n",
    "\n",
    "nowcast_method = nowcasts.get_method(\"sprog\")\n",
    "R_f = nowcast_method(\n",
    "    R[-3:, :, :],\n",
    "    V,\n",
    "    n_leadtimes,\n",
    "    n_cascade_levels=6,\n",
    "    precip_thr=precip_thr,\n",
    "    extrap_method='semilagrangian',\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "method = 'STEPS S-PROG'\n",
    "df = pd.read_csv(r\"G:\\My Drive\\PowPow\\Resort Graphs\\forecast_radar\\calc_duration.csv\")\n",
    "# Create a new row with the variables as columns\n",
    "new_row = {\"method\": method,\"num_prev_files\": num_prev_files,\"n_ens_members\": n_ens_members,\"n_leadtimes\": n_leadtimes,\"seed\": seed,\"execution_time\": execution_time,}\n",
    "# Convert the new row to a DataFrame\n",
    "new_row_df = pd.DataFrame([new_row])\n",
    "# Concatenate the original DataFrame with the new row DataFrame\n",
    "df = pd.concat([df, new_row_df], ignore_index=True)\n",
    "# Save the modified DataFrame to a new CSV file\n",
    "df.to_csv(r\"G:\\My Drive\\PowPow\\Resort Graphs\\forecast_radar\\calc_duration.csv\", index=False)\n",
    "\n",
    "# Back-transform to rain rate\n",
    "# R_f = transformation.dB_transform(R_f, threshold=-10.0, inverse=True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d11c93a-5640-4b47-9261-7f01c88fd9b9",
   "metadata": {},
   "source": [
    "## Create S-PROG v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c52571f-2a6a-40aa-8c52-7b041e744e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "# Estimate the motion field\n",
    "from pysteps import motion\n",
    "V = dense_lucaskanade(R)\n",
    "\n",
    "nowcast_method = nowcasts.get_method(\"sprog\")\n",
    "R_f_v2 = nowcast_method(\n",
    "    R[-3:, :, :],\n",
    "    V,\n",
    "    n_leadtimes,\n",
    "    n_cascade_levels=6,\n",
    "    precip_thr=precip_thr,\n",
    "    extrap_method='semilagrangian',\n",
    "    probmatching_method=\"cdf\"\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "method = 'STEPS S-PROG v2'\n",
    "df = pd.read_csv(r\"G:\\My Drive\\PowPow\\Resort Graphs\\forecast_radar\\calc_duration.csv\")\n",
    "# Create a new row with the variables as columns\n",
    "new_row = {\"method\": method,\"num_prev_files\": num_prev_files,\"n_ens_members\": n_ens_members,\"n_leadtimes\": n_leadtimes,\"seed\": seed,\"execution_time\": execution_time,}\n",
    "# Convert the new row to a DataFrame\n",
    "new_row_df = pd.DataFrame([new_row])\n",
    "# Concatenate the original DataFrame with the new row DataFrame\n",
    "df = pd.concat([df, new_row_df], ignore_index=True)\n",
    "# Save the modified DataFrame to a new CSV file\n",
    "df.to_csv(r\"G:\\My Drive\\PowPow\\Resort Graphs\\forecast_radar\\calc_duration.csv\", index=False)\n",
    "\n",
    "# Back-transform to rain rate\n",
    "# R_f_v2 = transformation.dB_transform(R_f_v2, threshold=-10.0, inverse=True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40275daf-529e-4934-9a03-652b124705d9",
   "metadata": {},
   "source": [
    "## Plot S-PROG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd4be3d-b571-4d8f-94c8-00ad2a158400",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(R_f.shape[0]):\n",
    "    f_step = i + 1\n",
    "    \n",
    "    # Add 8 minutes from the datetime object\n",
    "    new_date = date + timedelta(minutes=(f_step)*8)\n",
    "    # Format the new date as a string\n",
    "    new_date_string = new_date.strftime(\"%Y%m%d%H%M\")\n",
    "\n",
    "    # Get the extent values from metadata\n",
    "    x1 = metadata['x1']\n",
    "    x2 = metadata['x2']\n",
    "    y2 = metadata['y1']\n",
    "    y1 = metadata['y2']\n",
    "\n",
    "    # Create a grid of x and y coordinates\n",
    "    x = np.linspace(x1, x2, R.shape[2])\n",
    "    y = np.linspace(y1, y2, R.shape[1])\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "\n",
    "    bounds = [0.08, 0.16, 0.25,  0.40, 0.63, 1, 1.6, 2.5, 4, 6.3, 10, 16, 25, 40, 63, 100, 160, 220]\n",
    "    norm = colors.BoundaryNorm(boundaries=bounds, ncolors=len(bounds))\n",
    "    colormap = colors.ListedColormap(['#9e7c94', #grey\n",
    "                                      '#650064','#ae00b0','#dc01da', #purples 5-15\n",
    "                                      '#3531c3','#0b60f9', #blues\n",
    "                                      '#009697', '#00c930','#65ff01','#98ff00','#c6fe00', #greens\n",
    "                                      '#fffd04', #yellow\n",
    "                                      '#ffc802', '#ffa000','#ff7d01', #orange\n",
    "                                      '#df1a01','#8d0000' ]) #red           #65-75\n",
    "    \n",
    "    # Create the figure and subplots\n",
    "    # fig, axs = plt.subplots(1, 2, figsize=(18, 9), dpi=200, subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(12, 12), dpi=200, subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "\n",
    "    # Add features to both subplots\n",
    "    for ax in axs:\n",
    "        ax.add_feature(USCOUNTIES.with_scale('5m'), linewidth=.5, edgecolor='darkgrey')\n",
    "        ax.add_feature(cartopy.feature.STATES, linewidth=1, edgecolor='black')\n",
    "\n",
    "        # Set up the first subplot\n",
    "        axs[0].set_title(new_date_string + \" S-PROG (+ %i min)\" % (f_step * timestep))\n",
    "        axs[0].set_xlim(domain_lon)\n",
    "        axs[0].set_ylim(domain_lat)\n",
    "\n",
    "        # Set up the second subplot\n",
    "        axs[1].set_title(new_date_string + \" S-PROG v2 (+ %i min)\" % (f_step * timestep)) #'Placeholder for LINDA Deterministic')\n",
    "        axs[1].set_xlim(domain_lon)\n",
    "        axs[1].set_ylim(domain_lat)\n",
    "\n",
    "        # Plot in the subplots\n",
    "        axs[0].contourf(X, Y, R_f[i, :, :], levels=bounds, norm=norm, cmap=colormap)\n",
    "        axs[1].contourf(X, Y, R_f_v2[i, :, :], levels=bounds, norm=norm, cmap=colormap)\n",
    "        \n",
    "        # Plot 2.5mm contour\n",
    "        axs[0].contour(X, Y, R_f[i, :, :], levels=[.254], colors='black')\n",
    "        axs[1].contour(X, Y, R_f[i, :, :], levels=[.254], colors='black')\n",
    "\n",
    "    file_name=\"S-PROG + S-PROG v2 (+ %i min)\" % (f_step * timestep)\n",
    "    mrms_radar_path = os.path.join(r'G:\\My Drive\\PowPow\\Resort Graphs\\forecast_radar\\deterministic', file_name)\n",
    "    plt.savefig(mrms_radar_path+'.png',dpi=200,bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d8fc42-f01e-46f6-86a0-2e1014d23d7f",
   "metadata": {},
   "source": [
    "## STEPS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8d4853-6a63-4d40-999d-2bf92ef7aaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "# Estimate the motion field\n",
    "V = dense_lucaskanade(R)\n",
    "\n",
    "# The STEPS nowcast\n",
    "nowcast_method = nowcasts.get_method(\"steps\")\n",
    "R_f_ens = nowcast_method(\n",
    "    R[-3:, :, :],\n",
    "    V,\n",
    "    n_leadtimes,\n",
    "    n_ens_members,\n",
    "    n_cascade_levels=6,\n",
    "    precip_thr=precip_thr,\n",
    "    kmperpixel=2,\n",
    "    timestep=timestep,\n",
    "    # noise_method=\"nonparametric\",\n",
    "    vel_pert_method=\"bps\",\n",
    "    mask_method=\"incremental\",\n",
    "    seed=seed,\n",
    "    extrap_method='semilagrangian',\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "# Back-transform to rain rates\n",
    "# R_f_ens = transformation.dB_transform(R_f_ens, threshold=-10.0, inverse=True)[0]\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(\"Execution time:\", execution_time, \"seconds\")\n",
    "method = 'STEPS Ens'\n",
    "df = pd.read_csv(r\"G:\\My Drive\\PowPow\\Resort Graphs\\forecast_radar\\calc_duration.csv\")\n",
    "# Create a new row with the variables as columns\n",
    "new_row = {\"method\": method,\"num_prev_files\": num_prev_files,\"n_ens_members\": n_ens_members,\"n_leadtimes\": n_leadtimes,\"seed\": seed,\"execution_time\": execution_time,}\n",
    "\n",
    "# Convert the new row to a DataFrame\n",
    "new_row_df = pd.DataFrame([new_row])\n",
    "\n",
    "# Concatenate the original DataFrame with the new row DataFrame\n",
    "df = pd.concat([df, new_row_df], ignore_index=True)\n",
    "\n",
    "# Save the modified DataFrame to a new CSV file\n",
    "df.to_csv(r\"G:\\My Drive\\PowPow\\Resort Graphs\\forecast_radar\\calc_duration.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339990cd-d8f9-45f9-b9dc-6f1395a666d6",
   "metadata": {},
   "source": [
    "## STEPS v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6607dd-b068-4549-becd-1a5efa9b01d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "# Estimate the motion field\n",
    "V = dense_lucaskanade(R)\n",
    "\n",
    "# The STEPS nowcast\n",
    "nowcast_method = nowcasts.get_method(\"steps\")\n",
    "R_f_ens_v2 = nowcast_method(\n",
    "    R[-3:, :, :],\n",
    "    V,\n",
    "    n_leadtimes,\n",
    "    n_ens_members,\n",
    "    n_cascade_levels=6,\n",
    "    precip_thr=precip_thr,\n",
    "    kmperpixel=2,\n",
    "    timestep=timestep,\n",
    "    # noise_method=\"nonparametric\",\n",
    "    vel_pert_method=\"bps\",\n",
    "    mask_method=\"incremental\",\n",
    "    seed=seed,\n",
    "    extrap_method='semilagrangian',\n",
    "    num_workers=2,\n",
    "    probmatching_method=\"cdf\"\n",
    ")\n",
    "\n",
    "# Back-transform to rain rates\n",
    "# R_f_ens_v2 = transformation.dB_transform(R_f_ens_v2, threshold=-10.0, inverse=True)[0]\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(\"Execution time:\", execution_time, \"seconds\")\n",
    "method = 'STEPS Ens v2'\n",
    "df = pd.read_csv(r\"G:\\My Drive\\PowPow\\Resort Graphs\\forecast_radar\\calc_duration.csv\")\n",
    "# Create a new row with the variables as columns\n",
    "new_row = {\"method\": method,\"num_prev_files\": num_prev_files,\"n_ens_members\": n_ens_members,\"n_leadtimes\": n_leadtimes,\"seed\": seed,\"execution_time\": execution_time,}\n",
    "\n",
    "# Convert the new row to a DataFrame\n",
    "new_row_df = pd.DataFrame([new_row])\n",
    "\n",
    "# Concatenate the original DataFrame with the new row DataFrame\n",
    "df = pd.concat([df, new_row_df], ignore_index=True)\n",
    "\n",
    "# Save the modified DataFrame to a new CSV file\n",
    "df.to_csv(r\"G:\\My Drive\\PowPow\\Resort Graphs\\forecast_radar\\calc_duration.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b52282a-8e84-423e-98bd-21c9d784953b",
   "metadata": {},
   "source": [
    "## Plot STEPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0c5f24-d664-43d1-8204-30cdad8bfad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(R_f_ens.shape[1]):\n",
    "    f_step = i + 1\n",
    "    \n",
    "    # Add 8 minutes from the datetime object\n",
    "    new_date = date + timedelta(minutes=(f_step)*8)\n",
    "    # Format the new date as a string\n",
    "    new_date_string = new_date.strftime(\"%Y%m%d%H%M\")\n",
    "\n",
    "    # Get the extent values from metadata\n",
    "    x1 = metadata['x1']\n",
    "    x2 = metadata['x2']\n",
    "    y2 = metadata['y1']\n",
    "    y1 = metadata['y2']\n",
    "\n",
    "    # Create a grid of x and y coordinates\n",
    "    x = np.linspace(x1, x2, R.shape[2])\n",
    "    y = np.linspace(y1, y2, R.shape[1])\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "\n",
    "    bounds = [0.08, 0.16, 0.25,  0.40, 0.63, 1, 1.6, 2.5, 4, 6.3, 10, 16, 25, 40, 63, 100, 160, 220]\n",
    "    norm = colors.BoundaryNorm(boundaries=bounds, ncolors=len(bounds))\n",
    "    colormap = colors.ListedColormap(['#9e7c94', #grey\n",
    "                                      '#650064','#ae00b0','#dc01da', #purples 5-15\n",
    "                                      '#3531c3','#0b60f9', #blues\n",
    "                                      '#009697', '#00c930','#65ff01','#98ff00','#c6fe00', #greens\n",
    "                                      '#fffd04', #yellow\n",
    "                                      '#ffc802', '#ffa000','#ff7d01', #orange\n",
    "                                      '#df1a01','#8d0000' ]) #red           #65-75\n",
    "    \n",
    "    #Calulate the ensemble mean\n",
    "    R_f_mean = np.mean(R_f_ens[:, i, :, :], axis=0)\n",
    "    R_f_mean_v2 = np.mean(R_f_ens_v2[:, i, :, :], axis=0)\n",
    "    \n",
    "    # Create the figure and subplots\n",
    "    # fig, axs = plt.subplots(1, 2, figsize=(18, 9), dpi=200, subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(12, 12), dpi=200, subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "\n",
    "    # Add features to both subplots\n",
    "    for ax in axs:\n",
    "        ax.add_feature(USCOUNTIES.with_scale('5m'), linewidth=.5, edgecolor='darkgrey')\n",
    "        ax.add_feature(cartopy.feature.STATES, linewidth=1, edgecolor='black')\n",
    "\n",
    "        # Set up the first subplot\n",
    "        axs[0].set_title(new_date_string+\" STEPS Ens (+ %i min)\" % (f_step * timestep))\n",
    "        axs[0].set_xlim(domain_lon)\n",
    "        axs[0].set_ylim(domain_lat)\n",
    "\n",
    "        # Set up the second subplot\n",
    "        axs[1].set_title(new_date_string+\" STEPS Ens v2 (+ %i min)\" % (f_step * timestep))\n",
    "        axs[1].set_xlim(domain_lon)\n",
    "        axs[1].set_ylim(domain_lat)\n",
    "\n",
    "        # Plot in the first subplot\n",
    "        axs[0].contourf(X, Y, R_f_mean, levels=bounds, norm=norm, cmap=colormap)\n",
    "        axs[1].contourf(X, Y, R_f_mean_v2, levels=bounds, norm=norm, cmap=colormap)\n",
    "        \n",
    "        # Plot 2.5mm contour\n",
    "        axs[0].contour(X, Y, R_f_mean, levels=[.254], colors='black')\n",
    "        axs[1].contour(X, Y, R_f_mean_v2, levels=[.254], colors='black')\n",
    "    \n",
    "    file_name=\"STEPS + STEPS v2  (+ %i min)\" % (f_step * timestep)\n",
    "    mrms_radar_path = os.path.join(r'G:\\My Drive\\PowPow\\Resort Graphs\\forecast_radar\\ens', file_name)\n",
    "    plt.savefig(mrms_radar_path+'.png',dpi=200,bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6464d50a-2196-4c31-a714-019ae7ad84c2",
   "metadata": {},
   "source": [
    "## STEPS Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7386e7c8-3eec-44f8-842e-2ddc10043415",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(R_f_ens.shape[1]):\n",
    "    f_step = i + 1\n",
    "    \n",
    "    # Add 8 minutes from the datetime object\n",
    "    new_date = date + timedelta(minutes=(f_step)*8)\n",
    "    # Format the new date as a string\n",
    "    new_date_string = new_date.strftime(\"%Y%m%d%H%M\")\n",
    "\n",
    "    # Get the extent values from metadata\n",
    "    x1 = metadata['x1']\n",
    "    x2 = metadata['x2']\n",
    "    y2 = metadata['y1']\n",
    "    y1 = metadata['y2']\n",
    "\n",
    "    # Create a grid of x and y coordinates\n",
    "    x = np.linspace(x1, x2, R.shape[2])\n",
    "    y = np.linspace(y1, y2, R.shape[1])\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    \n",
    "    bounds = [0, 0.1, 0.2,  0.3, 0.4, .5, .6, .7, .8, .9, 1]\n",
    "    norm = colors.BoundaryNorm(boundaries=bounds, ncolors=len(bounds))\n",
    "    colormap = colors.ListedColormap(['#FFFFFF','#fff5f0', '#fee0d2', '#fcbba1', '#fc9272', '#fb6a4a', '#ef3b2c', '#cb181d', '#a50f15', '#67000d'])\n",
    "\n",
    "    P = excprob(R_f_ens[:, i, :, :], .254)\n",
    "    P_v2 = excprob(R_f_ens_v2[:, i, :, :], .254)\n",
    "    \n",
    "    #Calulate the ensemble mean\n",
    "    R_f_mean = np.mean(R_f_ens[:, i, :, :], axis=0)\n",
    "    R_f_mean_v2 = np.mean(R_f_ens_v2[:, i, :, :], axis=0)\n",
    "    \n",
    "    # Create the figure and subplots\n",
    "    # fig, axs = plt.subplots(1, 2, figsize=(18, 14), dpi=200, subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(12, 12), dpi=200, subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "    for ax in axs:\n",
    "        ax.add_feature(USCOUNTIES.with_scale('5m'), linewidth=.5, edgecolor='darkgrey')\n",
    "        ax.add_feature(cartopy.feature.STATES, linewidth=1, edgecolor='black')\n",
    "\n",
    "        # Set up the first subplot\n",
    "        axs[0].set_title(new_date_string+\" Exceedence Probability .01 inch (+ %i min)\" % (f_step * timestep))\n",
    "        axs[0].set_xlim(domain_lon)\n",
    "        axs[0].set_ylim(domain_lat)\n",
    "\n",
    "        # Set up the second subplot\n",
    "        axs[1].set_title(new_date_string+\" v2 Exceedence Probability .01 inch (+ %i min)\" % (f_step * timestep))\n",
    "        axs[1].set_xlim(domain_lon)\n",
    "        axs[1].set_ylim(domain_lat)\n",
    "\n",
    "        # Plot in the first subplot\n",
    "        axs[0].contourf(X, Y, P, levels=bounds, norm=norm, cmap=colormap)\n",
    "        axs[1].contourf(X, Y, P_v2, levels=bounds, norm=norm, cmap=colormap)\n",
    "        \n",
    "        # Plot 2.5mm contour\n",
    "        axs[0].contour(X, Y, R_f_mean, levels=[.254], colors='black')\n",
    "        axs[1].contour(X, Y, R_f_mean_v2, levels=[.254], colors='black')\n",
    "\n",
    "    # plt.tight_layout()\n",
    "    file_name=\"Exceedence probability (+ %i min)\" % (f_step * timestep)\n",
    "    mrms_radar_path = os.path.join(r'G:\\My Drive\\PowPow\\Resort Graphs\\forecast_radar\\prob', file_name)\n",
    "    plt.savefig(mrms_radar_path+'.png',dpi=200,bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5a068b-781c-4219-938a-d2b15ebb4144",
   "metadata": {},
   "source": [
    "## Create Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736c3682-2a66-4a60-b468-e7c7104f9c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source folder directories\n",
    "folder1 = r\"G:\\My Drive\\PowPow\\Resort Graphs\\forecast_radar\\mrms\"\n",
    "folder2 = r\"G:\\My Drive\\PowPow\\Resort Graphs\\forecast_radar\\deterministic\" \n",
    "\n",
    "# Output GIF file path\n",
    "output_gif = r\"G:\\My Drive\\PowPow\\Resort Graphs\\forecast_radar\\deterministic\\case_studies\\deterministic_\"+domain_name+gif_date_start+\".gif\"\n",
    "print(output_gif)\n",
    "# List to store image paths\n",
    "image_paths = []\n",
    "\n",
    "# Function to get all PNG files from a folder\n",
    "def get_png_files(folder):\n",
    "    png_files = []\n",
    "    for file in os.listdir(folder):\n",
    "        if file.endswith(\".png\"):\n",
    "            file_path = os.path.join(folder, file)\n",
    "            png_files.append(file_path)\n",
    "    return png_files\n",
    "\n",
    "# Get PNG files from folder1\n",
    "image_paths1 = get_png_files(folder1)\n",
    "\n",
    "# Get PNG files from folder2\n",
    "image_paths2 = get_png_files(folder2)\n",
    "\n",
    "# Concatenate the image paths\n",
    "image_paths = image_paths1 + image_paths2\n",
    "\n",
    "# Sort the image paths in alphanumeric order\n",
    "# image_paths.sort()\n",
    "\n",
    "# Create GIF from the image paths\n",
    "images = []\n",
    "for image_path in image_paths:\n",
    "    image = Image.open(image_path)\n",
    "    images.append(image)\n",
    "\n",
    "# Save the GIF with the original image resolution\n",
    "images[0].save(output_gif, save_all=True, append_images=images[1:], optimize=False, duration=300, loop=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3bf9c8-e692-4d60-80fc-27b1eb045a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source folder directories\n",
    "folder1 = r\"G:\\My Drive\\PowPow\\Resort Graphs\\forecast_radar\\mrms\"\n",
    "folder2 = r\"G:\\My Drive\\PowPow\\Resort Graphs\\forecast_radar\\ens\" \n",
    "\n",
    "# Output GIF file path\n",
    "output_gif = r\"G:\\My Drive\\PowPow\\Resort Graphs\\forecast_radar\\ens\\case_studies\\ens_\"+domain_name+gif_date_start+\".gif\"\n",
    "\n",
    "# List to store image paths\n",
    "image_paths = []\n",
    "\n",
    "# Function to get all PNG files from a folder\n",
    "def get_png_files(folder):\n",
    "    png_files = []\n",
    "    for file in os.listdir(folder):\n",
    "        if file.endswith(\".png\"):\n",
    "            file_path = os.path.join(folder, file)\n",
    "            png_files.append(file_path)\n",
    "    return png_files\n",
    "\n",
    "# Get PNG files from folder1\n",
    "image_paths1 = get_png_files(folder1)\n",
    "\n",
    "# Get PNG files from folder2\n",
    "image_paths2 = get_png_files(folder2)\n",
    "\n",
    "# Concatenate the image paths\n",
    "image_paths = image_paths1 + image_paths2\n",
    "\n",
    "# Sort the image paths in alphanumeric order\n",
    "# image_paths.sort()\n",
    "\n",
    "# Create GIF from the image paths\n",
    "images = []\n",
    "for image_path in image_paths:\n",
    "    image = Image.open(image_path)\n",
    "    images.append(image)\n",
    "\n",
    "# Save the GIF with the original image resolution\n",
    "images[0].save(output_gif, save_all=True, append_images=images[1:], optimize=False, duration=300, loop=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f9e423-e792-4188-aaf7-b86f2aab9d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source folder directories\n",
    "folder1 = r\"G:\\My Drive\\PowPow\\Resort Graphs\\forecast_radar\\mrms\"\n",
    "folder2 = r\"G:\\My Drive\\PowPow\\Resort Graphs\\forecast_radar\\prob\" \n",
    "\n",
    "# Output GIF file path\n",
    "output_gif = r\"G:\\My Drive\\PowPow\\Resort Graphs\\forecast_radar\\prob\\case_studies\\prob_\"+domain_name+gif_date_start+\".gif\"\n",
    "\n",
    "# List to store image paths\n",
    "image_paths = []\n",
    "\n",
    "# Function to get all PNG files from a folder\n",
    "def get_png_files(folder):\n",
    "    png_files = []\n",
    "    for file in os.listdir(folder):\n",
    "        if file.endswith(\".png\"):\n",
    "            file_path = os.path.join(folder, file)\n",
    "            png_files.append(file_path)\n",
    "    return png_files\n",
    "\n",
    "# Get PNG files from folder1\n",
    "image_paths1 = get_png_files(folder1)\n",
    "\n",
    "# Get PNG files from folder2\n",
    "image_paths2 = get_png_files(folder2)\n",
    "\n",
    "# Concatenate the image paths\n",
    "image_paths = image_paths1 + image_paths2\n",
    "\n",
    "# Sort the image paths in alphanumeric order\n",
    "# image_paths.sort()\n",
    "\n",
    "# Create GIF from the image paths\n",
    "images = []\n",
    "for image_path in image_paths:\n",
    "    image = Image.open(image_path)\n",
    "    images.append(image)\n",
    "\n",
    "# Save the GIF with the original image resolution\n",
    "images[0].save(output_gif, save_all=True, append_images=images[1:], optimize=False, duration=300, loop=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697018f8-abd5-4767-84ec-b51875aa9531",
   "metadata": {},
   "source": [
    "## Ens Members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1dcab2-6b28-4e04-a663-fe4800c388d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot some of the realizations\n",
    "fig = plt.figure()#figsize=(12, 12))\n",
    "for i in range(20):\n",
    "    ax = fig.add_subplot(5,4,i+1)#441 + i)\n",
    "    ax = plot_precip_field(\n",
    "        R_f_ens[i, -1, :, :], geodata=metadata, colorbar=False, axis=\"off\",bbox = [-110, 36.7, -101, 41.5],\n",
    "    )\n",
    "    ax.set_title(\"Member %02d\" % i)\n",
    "plt.tight_layout()\n",
    "plt.savefig('ens_co.png',dpi=200,bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a932c7c6-4d8a-4e95-b415-a3a28b97f83f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b437681f-6748-4fff-8c29-db53ddc1d9a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97768a4d-4ff3-4927-92ea-5c27c1699154",
   "metadata": {},
   "source": [
    "## LINDA Deterministic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17403f47-1319-4c58-aca3-f8c3f6ff63fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# start_time = time.time()\n",
    "\n",
    "# from pysteps.nowcasts import linda, sprog, steps\n",
    "# # Estimate the motion field\n",
    "# from pysteps import motion\n",
    "# V = dense_lucaskanade(R)\n",
    "# # Compute 30-minute LINDA nowcast with 8 parallel workers\n",
    "# # Restrict the number of features to 15 to reduce computation time\n",
    "# nowcast_linda = linda.forecast(\n",
    "#     R[-3:, :, :], #rainrate,\n",
    "#     V, #advection,\n",
    "#     n_leadtimes, #6,\n",
    "#     max_num_features= 5, #15,\n",
    "#     add_perturbations=False,\n",
    "#     num_workers=12, #8\n",
    "#     measure_time=True,\n",
    "#     kmperpixel=4,\n",
    "# )[0]\n",
    "\n",
    "# end_time = time.time()\n",
    "# execution_time = end_time - start_time\n",
    "# method = 'LINDA Deterministic'\n",
    "# df = pd.read_csv(r\"G:\\My Drive\\PowPow\\Resort Graphs\\forecast_radar\\calc_duration.csv\")\n",
    "# # Create a new row with the variables as columns\n",
    "# new_row = {\"method\": method,\"num_prev_files\": num_prev_files,\"n_ens_members\": n_ens_members,\"n_leadtimes\": n_leadtimes,\"seed\": seed,\"execution_time\": execution_time,}\n",
    "# # Convert the new row to a DataFrame\n",
    "# new_row_df = pd.DataFrame([new_row])\n",
    "# # Concatenate the original DataFrame with the new row DataFrame\n",
    "# df = pd.concat([df, new_row_df], ignore_index=True)\n",
    "# # Save the modified DataFrame to a new CSV file\n",
    "# df.to_csv(r\"G:\\My Drive\\PowPow\\Resort Graphs\\forecast_radar\\calc_duration.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c897658-3eb7-450a-959d-54d6cf0d1e5d",
   "metadata": {},
   "source": [
    "## STEPS Ensemble Single Pane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1475a6-b800-4c31-910e-a4c2a3a67b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # The STEPS nowcast\n",
    "# nowcast_method = nowcasts.get_method(\"steps\")\n",
    "# R_f = nowcast_method(\n",
    "#     R[-3:, :, :],\n",
    "#     V,\n",
    "#     n_leadtimes,\n",
    "#     n_ens_members,\n",
    "#     n_cascade_levels=6,\n",
    "#     # R_thr=-10.0,\n",
    "#     precip_thr=-10.0,\n",
    "#     kmperpixel=2,\n",
    "#     timestep=timestep,\n",
    "#     noise_method=\"nonparametric\",\n",
    "#     vel_pert_method=\"bps\",\n",
    "#     mask_method=\"incremental\",\n",
    "#     seed=seed,\n",
    "# )\n",
    "\n",
    "# # Back-transform to rain rates\n",
    "# R_f = transformation.dB_transform(R_f, threshold=-10.0, inverse=True)[0]\n",
    "\n",
    "# for i in range(R_f.shape[1]):\n",
    "#     f_step = i + 1\n",
    "#     #fig size\n",
    "#     plt.figure(figsize=(12, 6.5), dpi=100)\n",
    "#     ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "#     ax.add_feature(USCOUNTIES.with_scale('5m'),linewidth=.5,edgecolor='darkgrey')\n",
    "#     ax.add_feature(cartopy.feature.STATES,linewidth=1,edgecolor='black')\n",
    "    \n",
    "#     # Add 8 minutes from the datetime object\n",
    "#     new_date = date + timedelta(minutes=(f_step)*8)\n",
    "#     # Format the new date as a string\n",
    "#     new_date_string = new_date.strftime(\"%Y%m%d%H%M\")\n",
    "\n",
    "#     # Get the extent values from metadata\n",
    "#     x1 = metadata['x1']\n",
    "#     x2 = metadata['x2']\n",
    "#     y2 = metadata['y1']\n",
    "#     y1 = metadata['y2']\n",
    "\n",
    "#     # Create a grid of x and y coordinates\n",
    "#     x = np.linspace(x1, x2, R.shape[2])\n",
    "#     y = np.linspace(y1, y2, R.shape[1])\n",
    "#     X, Y = np.meshgrid(x, y)\n",
    "\n",
    "#     bounds = [0.08, 0.16, 0.25,  0.40, 0.63, 1, 1.6, 2.5, 4, 6.3, 10, 16, 25, 40, 63, 100, 160, 220]\n",
    "#     norm = colors.BoundaryNorm(boundaries=bounds, ncolors=len(bounds))\n",
    "#     colormap = colors.ListedColormap(['#9e7c94', #grey\n",
    "#                                       '#650064','#ae00b0','#dc01da', #purples 5-15\n",
    "#                                       '#3531c3','#0b60f9', #blues\n",
    "#                                       '#009697', '#00c930','#65ff01','#98ff00','#c6fe00', #greens\n",
    "#                                       '#fffd04', #yellow\n",
    "#                                       '#ffc802', '#ffa000','#ff7d01', #orange\n",
    "#                                       '#df1a01','#8d0000' ]) #red           #65-75\n",
    "#     # print(R_f[:,:,:,:].shape)\n",
    "#     # Plot the S-PROG forecast using contourf\n",
    "#     R_f_mean = np.mean(R_f[:, i, :, :], axis=0)\n",
    "#     # print(R_f_mean.shape)\n",
    "#     plt.contourf(X, Y, R_f_mean, levels=bounds, norm=norm, cmap=colormap)\n",
    "    \n",
    "#     plt.title(new_date_string+\" Ensemble mean (+ %i min)\" % (f_step * timestep))\n",
    "#     plt.colorbar(label='Rain Rate (mm/h)')\n",
    "\n",
    "#     # Set the plot limits\n",
    "#     plt.xlim(-110, -101)\n",
    "#     plt.ylim(36.7, 41.5)\n",
    "    \n",
    "#     # # Plot the S-PROG forecast\n",
    "#     # R_f_mean = np.mean(R_f[:, i, :, :], axis=0)\n",
    "#     # plot_precip_field(\n",
    "#     #     R_f_mean,\n",
    "#     #     geodata=metadata,\n",
    "#     #     title=new_date_string+\"Ensemble mean (+ %i min)\" % (f_step * timestep),\n",
    "#     #     bbox = [-110, 36.7, -101, 41.5],\n",
    "#     # )\n",
    "#     file_name=\"Ensemble mean (+ %i min)\" % (f_step * timestep)\n",
    "#     mrms_radar_path = os.path.join(r'G:\\My Drive\\PowPow\\Resort Graphs\\forecast_radar\\ens', file_name)\n",
    "#     plt.savefig(mrms_radar_path+'.png',dpi=200,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea25393e-fc4b-4bee-801c-e211a20dec79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f105d80-f156-4c7d-9696-5312aece3968",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368a24bc-50ea-44e5-ab1d-66790364d0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # P = excprob(R_f[:, -1, :, :], 0.5)\n",
    "\n",
    "# for i in range(R_f.shape[1]):\n",
    "#     f_step = i + 1\n",
    "#     #fig size\n",
    "#     plt.figure(figsize=(12, 6.5), dpi=100)\n",
    "#     ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "#     ax.add_feature(cartopy.feature.STATES,linewidth=1,edgecolor='darkgray')\n",
    "#     ax.add_feature(USCOUNTIES.with_scale('5m'),linewidth=.5,edgecolor='darkgrey')\n",
    "#     P = excprob(R_f[:, i, :, :], 2.54)\n",
    "#     print(P.shape)\n",
    "#     # Add 8 minutes from the datetime object\n",
    "#     new_date = date + timedelta(minutes=(f_step)*8)\n",
    "#     # Format the new date as a string\n",
    "#     new_date_string = new_date.strftime(\"%Y%m%d%H%M\")   \n",
    "    \n",
    "#     plot_precip_field(\n",
    "#         P,\n",
    "#         geodata=metadata,\n",
    "#         ptype=\"prob\",\n",
    "#         units=\"mm/h\",\n",
    "#         probthr=2.54,\n",
    "#         title=new_date_string+\"Exceedence probability .1 inch (+ %i min)\" % (f_step * timestep),\n",
    "#         bbox = [-110, 36.7, -101, 41.5],\n",
    "#     )\n",
    "#     file_name=\"Exceedence probability (+ %i min)\" % (f_step * timestep)\n",
    "#     # mrms_radar_path = os.path.join(r'G:\\My Drive\\PowPow\\Resort Graphs\\forecast_radar\\prob', file_name)\n",
    "#     # plt.savefig(mrms_radar_path+'.png',dpi=200,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81912aad-bbf8-4558-8fcb-57c689edc4f7",
   "metadata": {},
   "source": [
    "## MRMS Single Pane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344ee8a9-bdc8-4f3f-b06c-9822898d581a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# date = datetime.strptime(formatted_datetime, \"%Y%m%d%H%M\")\n",
    "# data_source = \"mrms_os\"      \n",
    "# from pysteps.visualization.basemaps import plot_map_cartopy\n",
    "\n",
    "# # Load data source config\n",
    "# # data_source = \"mrms_os\"\n",
    "# root_path = rcparams.data_sources[data_source][\"root_path\"]\n",
    "# path_fmt = rcparams.data_sources[data_source][\"path_fmt\"]\n",
    "# fn_pattern = rcparams.data_sources[data_source][\"fn_pattern\"]\n",
    "# fn_ext = rcparams.data_sources[data_source][\"fn_ext\"]\n",
    "# importer_name = rcparams.data_sources[data_source][\"importer\"]\n",
    "# importer_kwargs = rcparams.data_sources[data_source][\"importer_kwargs\"]\n",
    "# timestep = rcparams.data_sources[data_source][\"timestep\"]\n",
    "# num_prev_files = 4\n",
    "\n",
    "# # Find the radar files in the archive\n",
    "# fns = io.find_by_date(\n",
    "#     date, root_path, path_fmt, fn_pattern, fn_ext, timestep, num_prev_files\n",
    "# )\n",
    "\n",
    "# # Read the data from the archive\n",
    "# importer = io.get_method(importer_name, \"importer\")\n",
    "# R, _, metadata = io.read_timeseries(fns, importer, **importer_kwargs)\n",
    "\n",
    "# # Convert to rain rate\n",
    "# R, metadata = conversion.to_rainrate(R, metadata)\n",
    "\n",
    "# # Upscale data to 2 km to limit memory usage\n",
    "# # R, metadata = dimension.aggregate_fields_space(R, metadata, 2000)\n",
    "\n",
    "# for i in range(R.shape[0]):\n",
    "#     if i == 0:\n",
    "#         f_step = 32\n",
    "#     elif i == 1:\n",
    "#         f_step = 24\n",
    "#     elif i == 2:\n",
    "#         f_step = 16\n",
    "#     elif i == 3:\n",
    "#         f_step = 8\n",
    "#     elif i == 4:\n",
    "#         f_step = 0\n",
    "\n",
    "#     # fig size\n",
    "#     plt.figure(figsize=(12, 6.5), dpi=200)\n",
    "#     ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "#     ax.add_feature(USCOUNTIES.with_scale('5m'), linewidth=.5, edgecolor='darkgrey')\n",
    "#     ax.add_feature(cartopy.feature.STATES, linewidth=1, edgecolor='black')\n",
    "\n",
    "#     # Subtract 8 minutes from the datetime object\n",
    "#     new_date = date - timedelta(minutes=(num_prev_files - i) * 8)\n",
    "#     # Format the new date as a string\n",
    "#     new_date_string = new_date.strftime(\"%Y%m%d%H%M\")\n",
    "\n",
    "#     # Get the extent values from metadata\n",
    "#     x1 = metadata['x1']\n",
    "#     x2 = metadata['x2']\n",
    "#     y2 = metadata['y1']\n",
    "#     y1 = metadata['y2']\n",
    "\n",
    "#     # Create a grid of x and y coordinates\n",
    "#     x = np.linspace(x1, x2, R.shape[2])\n",
    "#     y = np.linspace(y1, y2, R.shape[1])\n",
    "#     X, Y = np.meshgrid(x, y)\n",
    "\n",
    "#     bounds = [0.08, 0.16, 0.25,  0.40, 0.63, 1, 1.6, 2.5, 4, 6.3, 10, 16, 25, 40, 63, 100, 160, 220]\n",
    "#     norm = colors.BoundaryNorm(boundaries=bounds, ncolors=len(bounds))\n",
    "#     colormap = colors.ListedColormap(['#9e7c94', #grey\n",
    "#                                       '#650064','#ae00b0','#dc01da', #purples 5-15\n",
    "#                                       '#3531c3','#0b60f9', #blues\n",
    "#                                       '#009697', '#00c930','#65ff01','#98ff00','#c6fe00', #greens\n",
    "#                                       '#fffd04', #yellow\n",
    "#                                       '#ffc802', '#ffa000','#ff7d01', #orange\n",
    "#                                       '#df1a01','#8d0000' ]) #red           #65-75\n",
    "#     # Plot the S-PROG forecast using contourf\n",
    "#     plt.contourf(X, Y, R[i, :, :], levels=bounds, norm=norm, cmap=colormap)\n",
    "\n",
    "#     plt.title(new_date_string + \" MRMS (-%i min)\" % (f_step))\n",
    "#     plt.colorbar(label='Rain Rate (mm/h)')\n",
    "\n",
    "#     # Set the plot limits\n",
    "#     plt.xlim(-110, -101)\n",
    "#     plt.ylim(36.7, 41.5)\n",
    "\n",
    "#     file_name=str(i)+\"_MRMS (-%i min)\" % (f_step)\n",
    "#     mrms_radar_path = os.path.join(r'G:\\My Drive\\PowPow\\Resort Graphs\\forecast_radar\\mrms', file_name)\n",
    "#     plt.savefig(mrms_radar_path+'.png', dpi=200, bbox_inches='tight')\n",
    "#     # plt.show()\n",
    "\n",
    "# # Log-transform the data to unit of dBR, set the threshold to 0.1 mm/h,\n",
    "# # set the fill value to -15 dBR\n",
    "# R, metadata = transformation.dB_transform(R, metadata, threshold=0.1, zerovalue=-15.0)\n",
    "\n",
    "# # Set missing values with the fill value\n",
    "# R[~np.isfinite(R)] = -15.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40baf45-f7da-475b-b8f3-095740abe0b7",
   "metadata": {},
   "source": [
    "## Single Plane S-PROG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7df544-137d-4066-8681-8c2dfbf630ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Single Plane S-PROG\n",
    "# # Estimate the motion field\n",
    "# from pysteps import motion\n",
    "# V = dense_lucaskanade(R)\n",
    "\n",
    "# nowcast_method = nowcasts.get_method(\"sprog\")\n",
    "# R_f = nowcast_method(\n",
    "#     R[-3:, :, :],\n",
    "#     V,\n",
    "#     n_leadtimes,\n",
    "#     n_cascade_levels=6,\n",
    "#     # R_thr=-10.0,\n",
    "#     precip_thr=-10.0,\n",
    "\n",
    "# )\n",
    "\n",
    "# # Back-transform to rain rate\n",
    "# R_f = transformation.dB_transform(R_f, threshold=-10.0, inverse=True)[0]\n",
    "\n",
    "# for i in range(R_f.shape[0]):\n",
    "#     f_step = i + 1\n",
    "#     #fig size\n",
    "#     plt.figure(figsize=(12, 6.5), dpi=100)\n",
    "#     ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "#     ax.add_feature(USCOUNTIES.with_scale('5m'),linewidth=.5,edgecolor='darkgrey')\n",
    "#     ax.add_feature(cartopy.feature.STATES,linewidth=1,edgecolor='black')\n",
    "    \n",
    "#     # Add 8 minutes from the datetime object\n",
    "#     new_date = date + timedelta(minutes=(f_step)*8)\n",
    "#     # Format the new date as a string\n",
    "#     new_date_string = new_date.strftime(\"%Y%m%d%H%M\")\n",
    "\n",
    "#     # Get the extent values from metadata\n",
    "#     x1 = metadata['x1']\n",
    "#     x2 = metadata['x2']\n",
    "#     y2 = metadata['y1']\n",
    "#     y1 = metadata['y2']\n",
    "\n",
    "#     # Create a grid of x and y coordinates\n",
    "#     x = np.linspace(x1, x2, R.shape[2])\n",
    "#     y = np.linspace(y1, y2, R.shape[1])\n",
    "#     X, Y = np.meshgrid(x, y)\n",
    "\n",
    "#     bounds = [0.08, 0.16, 0.25,  0.40, 0.63, 1, 1.6, 2.5, 4, 6.3, 10, 16, 25, 40, 63, 100, 160, 220]\n",
    "#     norm = colors.BoundaryNorm(boundaries=bounds, ncolors=len(bounds))\n",
    "#     colormap = colors.ListedColormap(['#9e7c94', #grey\n",
    "#                                       '#650064','#ae00b0','#dc01da', #purples 5-15\n",
    "#                                       '#3531c3','#0b60f9', #blues\n",
    "#                                       '#009697', '#00c930','#65ff01','#98ff00','#c6fe00', #greens\n",
    "#                                       '#fffd04', #yellow\n",
    "#                                       '#ffc802', '#ffa000','#ff7d01', #orange\n",
    "#                                       '#df1a01','#8d0000' ]) #red           #65-75\n",
    "#     # Plot the S-PROG forecast using contourf\n",
    "#     plt.contourf(X, Y, R_f[i, :, :], levels=bounds, norm=norm, cmap=colormap)\n",
    "\n",
    "#     plt.title(new_date_string+\" S-PROG (+ %i min)\" % (f_step * timestep))\n",
    "#     plt.colorbar(label='Rain Rate (mm/h)')\n",
    "\n",
    "#     # Set the plot limits\n",
    "#     plt.xlim(-110, -101)\n",
    "#     plt.ylim(36.7, 41.5)\n",
    "    \n",
    "#     # # Plot the S-PROG forecast\n",
    "#     # plot_precip_field(\n",
    "#     #     R_f[i, :, :],\n",
    "#     #     geodata=metadata,\n",
    "#     #     title=new_date_string+\" S-PROG (+ %i min)\" % (f_step * timestep),\n",
    "#     #     bbox = [-110, 36.7, -101, 41.5],\n",
    "#     # )\n",
    "#     file_name=\"S-PROG (+ %i min)\" % (f_step * timestep)\n",
    "#     mrms_radar_path = os.path.join(r'G:\\My Drive\\PowPow\\Resort Graphs\\forecast_radar\\deterministic', file_name)\n",
    "#     plt.savefig(mrms_radar_path+'.png',dpi=200,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b67b90-b33b-457b-b3fc-7f45d341badc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot some of the realizations\n",
    "# fig = plt.figure(figsize=(19, 10), dpi=100)\n",
    "# for i in range(4):\n",
    "#     ax = fig.add_subplot(221 + i)\n",
    "#     ax = plot_precip_field(\n",
    "#         R_f[i, -1, :, :], geodata=metadata, colorbar=False, axis=\"off\", bbox = [-110, 36.7, -101, 41.5],\n",
    "#     )\n",
    "#     ax.set_title(\"Member %02d\" % i)\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310bdf2f-924d-4915-a621-81df5a1cff8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# date = datetime.strptime(formatted_datetime, \"%Y%m%d%H%M\")\n",
    "# data_source = \"mrms_os\"      \n",
    "# from pysteps.visualization.basemaps import plot_map_cartopy\n",
    "\n",
    "# # Load data source config\n",
    "# root_path = rcparams.data_sources[data_source][\"root_path\"]\n",
    "# path_fmt = rcparams.data_sources[data_source][\"path_fmt\"]\n",
    "# fn_pattern = rcparams.data_sources[data_source][\"fn_pattern\"]\n",
    "# fn_ext = rcparams.data_sources[data_source][\"fn_ext\"]\n",
    "# importer_name = rcparams.data_sources[data_source][\"importer\"]\n",
    "# importer_kwargs = rcparams.data_sources[data_source][\"importer_kwargs\"]\n",
    "# timestep = rcparams.data_sources[data_source][\"timestep\"]\n",
    "# num_prev_files=4\n",
    "# # Find the radar files in the archive\n",
    "# fns = io.find_by_date(\n",
    "#     date, root_path, path_fmt, fn_pattern, fn_ext, timestep, num_prev_files\n",
    "# )\n",
    "# # Read the data from the archive\n",
    "# importer = io.get_method(importer_name, \"importer\")\n",
    "# R, _, metadata = io.read_timeseries(fns, importer, **importer_kwargs)\n",
    "\n",
    "# # Convert to rain rate\n",
    "# R, metadata = conversion.to_rainrate(R, metadata)\n",
    "\n",
    "# # Upscale data to 2 km to limit memory usage\n",
    "# # R, metadata = dimension.aggregate_fields_space(R, metadata, 2000)\n",
    "\n",
    "# for i in range(R.shape[0]):\n",
    "#     if i == 0:\n",
    "#         f_step = 32\n",
    "#     elif i == 1:\n",
    "#         f_step = 24\n",
    "#     elif i == 2:\n",
    "#         f_step = 16\n",
    "#     elif i == 3:\n",
    "#         f_step = 8\n",
    "#     elif i == 4:\n",
    "#         f_step = 0\n",
    "#     #fig size\n",
    "#     plt.figure(figsize=(12, 6.5), dpi=200)\n",
    "#     ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "#     ax.add_feature(USCOUNTIES.with_scale('5m'),linewidth=.5,edgecolor='darkgrey')\n",
    "#     ax.add_feature(cartopy.feature.STATES,linewidth=1,edgecolor='black')\n",
    "    \n",
    "#     # Subtract 8 minutes from the datetime object\n",
    "#     new_date = date - timedelta(minutes=(num_prev_files-i)*8)\n",
    "#     # Format the new date as a string\n",
    "#     new_date_string = new_date.strftime(\"%Y%m%d%H%M\")\n",
    "    \n",
    "#     # Plot the S-PROG forecast\n",
    "#     plot_precip_field(\n",
    "#         R[i, :, :],\n",
    "#         geodata=metadata,\n",
    "#         title=new_date_string+\" MRMS (-%i min)\" % (f_step),\n",
    "#         bbox = [-110, 36.7, -101, 41.5],\n",
    "#     )    \n",
    "#     file_name=str(i)+\"_MRMS (-%i min)\" % (f_step)\n",
    "#     mrms_radar_path = os.path.join(r'G:\\My Drive\\PowPow\\Resort Graphs\\forecast_radar\\mrms', file_name)\n",
    "#     plt.savefig(mrms_radar_path+'.png',dpi=200,bbox_inches='tight')\n",
    "#     # plt.show()\n",
    "\n",
    "# # Log-transform the data to unit of dBR, set the threshold to 0.1 mm/h,\n",
    "# # set the fill value to -15 dBR\n",
    "# R, metadata = transformation.dB_transform(R, metadata, threshold=0.1, zerovalue=-15.0)\n",
    "\n",
    "# # Set missing values with the fill value\n",
    "# R[~np.isfinite(R)] = -15.0\n",
    "\n",
    "# # Nicely print the metadata\n",
    "# # pprint(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2be47c8-6b82-4994-8671-6033b52cb024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Compute exceedence probabilities for a 0.5 mm/h threshold\n",
    "# P = excprob(R_f[:, -1, :, :], 0.5)\n",
    "\n",
    "# # Plot the field of probabilities\n",
    "# plt.figure(figsize=(19, 10), dpi=100)\n",
    "# plot_precip_field(\n",
    "#     P,\n",
    "#     geodata=metadata,\n",
    "#     ptype=\"prob\",\n",
    "#     units=\"mm/h\",\n",
    "#     probthr=0.5,\n",
    "#     title=\"Exceedence probability (+ %i min)\" % (n_leadtimes * timestep),\n",
    "# )\n",
    "# plt.show()\n",
    "\n",
    "# # sphinx_gallery_thumbnail_number = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7239882d-454f-4df4-af15-164d794e2bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# date = datetime.strptime(formatted_datetime, \"%Y%m%d%H%M\")\n",
    "# data_source = \"mrms_os\"      \n",
    "# from pysteps.visualization.basemaps import plot_map_cartopy\n",
    "\n",
    "# # Load data source config\n",
    "# # data_source = \"mrms_os\"\n",
    "# root_path = rcparams.data_sources[data_source][\"root_path\"]\n",
    "# path_fmt = rcparams.data_sources[data_source][\"path_fmt\"]\n",
    "# fn_pattern = rcparams.data_sources[data_source][\"fn_pattern\"]\n",
    "# fn_ext = rcparams.data_sources[data_source][\"fn_ext\"]\n",
    "# importer_name = rcparams.data_sources[data_source][\"importer\"]\n",
    "# importer_kwargs = rcparams.data_sources[data_source][\"importer_kwargs\"]\n",
    "# timestep = rcparams.data_sources[data_source][\"timestep\"]\n",
    "# num_prev_files = 4\n",
    "\n",
    "# # Find the radar files in the archive\n",
    "# fns = io.find_by_date(\n",
    "#     date, root_path, path_fmt, fn_pattern, fn_ext, timestep, num_prev_files\n",
    "# )\n",
    "\n",
    "# # Read the data from the archive\n",
    "# importer = io.get_method(importer_name, \"importer\")\n",
    "# R, _, metadata = io.read_timeseries(fns, importer, **importer_kwargs)\n",
    "\n",
    "# # Convert to rain rate\n",
    "# R, metadata = conversion.to_rainrate(R, metadata)\n",
    "\n",
    "# # Upscale data to 2 km to limit memory usage\n",
    "# # R, metadata = dimension.aggregate_fields_space(R, metadata, 2000)\n",
    "\n",
    "# for i in range(R.shape[0]):\n",
    "#     if i == 0:\n",
    "#         f_step = 32\n",
    "#     elif i == 1:\n",
    "#         f_step = 24\n",
    "#     elif i == 2:\n",
    "#         f_step = 16\n",
    "#     elif i == 3:\n",
    "#         f_step = 8\n",
    "#     elif i == 4:\n",
    "#         f_step = 0\n",
    "\n",
    "#     # Subtract 8 minutes from the datetime object\n",
    "#     new_date = date - timedelta(minutes=(num_prev_files - i) * 8)\n",
    "#     # Format the new date as a string\n",
    "#     new_date_string = new_date.strftime(\"%Y%m%d%H%M\")\n",
    "\n",
    "#     # Create the figure and subplots\n",
    "#     fig, axs = plt.subplots(1, 2, figsize=(18, 9), dpi=200, subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "\n",
    "#     # Add features to both subplots\n",
    "#     for ax in axs:\n",
    "#         ax.add_feature(USCOUNTIES.with_scale('5m'), linewidth=.5, edgecolor='darkgrey')\n",
    "#         ax.add_feature(cartopy.feature.STATES, linewidth=1, edgecolor='black')\n",
    "\n",
    "#     # Iterate over the subplots\n",
    "#     for ax in axs:\n",
    "#         # # Subtract 8 minutes from the datetime object\n",
    "#         # new_date = date - timedelta(minutes=(num_prev_files - i) * 8)\n",
    "#         # # Format the new date as a string\n",
    "#         # new_date_string = new_date.strftime(\"%Y%m%d%H%M\")\n",
    "\n",
    "#         # Get the extent values from metadata\n",
    "#         x1 = metadata['x1']\n",
    "#         x2 = metadata['x2']\n",
    "#         y2 = metadata['y1']\n",
    "#         y1 = metadata['y2']\n",
    "\n",
    "#         # Create a grid of x and y coordinates\n",
    "#         x = np.linspace(x1, x2, R.shape[2])\n",
    "#         y = np.linspace(y1, y2, R.shape[1])\n",
    "#         X, Y = np.meshgrid(x, y)\n",
    "\n",
    "#         bounds = [0.08, 0.16, 0.25, 0.40, 0.63, 1, 1.6, 2.5, 4, 6.3, 10, 16, 25, 40, 63, 100, 160, 220]\n",
    "#         norm = colors.BoundaryNorm(boundaries=bounds, ncolors=len(bounds))\n",
    "#         colormap = colors.ListedColormap(['#9e7c94', '#650064', '#ae00b0', '#dc01da', '#3531c3', '#0b60f9',\n",
    "#                                           '#009697', '#00c930', '#65ff01', '#98ff00', '#c6fe00', '#fffd04',\n",
    "#                                           '#ffc802', '#ffa000', '#ff7d01', '#df1a01', '#8d0000'])\n",
    "\n",
    "#         # Plot the S-PROG forecast using contourf\n",
    "#         ax.contourf(X, Y, R[i, :, :], levels=bounds, norm=norm, cmap=colormap)\n",
    "\n",
    "#         ax.set_title(new_date_string + \" MRMS (-%i min)\" % (f_step))\n",
    "#         # plt.colorbar(label='Rain Rate (mm/h)')\n",
    "\n",
    "#         # ax.set_colorbar(label='Rain Rate (mm/h)')\n",
    "\n",
    "#         ax.set_xlim(-110, -101)\n",
    "#         ax.set_ylim(36.7, 41.5)\n",
    "\n",
    "#     # Adjust the spacing between subplots\n",
    "#     plt.subplots_adjust(wspace=0.1)\n",
    "#     # plt.colorbar(label='Rain Rate (mm/h)')\n",
    "#     # Add a colorbar to the figure\n",
    "#     # cbar = fig.colorbar(axs[0].collections[0], ax=axs, label='Rain Rate (mm/h)')\n",
    "\n",
    "#     # Save the figure\n",
    "#     file_name = str(i) + \"_MRMS (-%i min)\" % (f_step)\n",
    "#     mrms_radar_path = os.path.join(r'G:\\My Drive\\PowPow\\Resort Graphs\\forecast_radar\\mrms', file_name)\n",
    "#     plt.savefig(mrms_radar_path + '.png', dpi=200, bbox_inches='tight')\n",
    "\n",
    "# # Log-transform the data to unit of dBR, set the threshold to 0.1 mm/h,\n",
    "# # set the fill value to -15 dBR\n",
    "# R, metadata = transformation.dB_transform(R, metadata, threshold=0.1, zerovalue=-15.0)\n",
    "\n",
    "# # Set missing values with the fill value\n",
    "# R[~np.isfinite(R)] = -15.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2978d478-6096-47fe-b0a9-e48f85b1d034",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0708f2d3-eb47-49fa-af00-9a49b9d58191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datetime import datetime\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import os\n",
    "# import numpy as np\n",
    "# import pygrib\n",
    "\n",
    "# folder_directory = r'C:\\Users\\16126\\pysteps_data\\mrms_op'\n",
    "\n",
    "# # Get a list of all files in the folder directory\n",
    "# files = os.listdir(folder_directory)\n",
    "\n",
    "# # Filter the list to include only the .grib2 files\n",
    "# grib2_files = [file for file in files if file.endswith('.grib2')]\n",
    "\n",
    "# # Sort the files if needed\n",
    "# grib2_files.sort()\n",
    "\n",
    "# # Load the data and metadata from the grib2 files into lists\n",
    "# data = []\n",
    "# metadata = []\n",
    "# for file in grib2_files:\n",
    "#     file_path = os.path.join(folder_directory, file)\n",
    "#     grbs = pygrib.open(file_path)\n",
    "    \n",
    "#     for grb in grbs:\n",
    "#         data.append(grb.values)\n",
    "#         metadata.append(grb)\n",
    "\n",
    "#     grbs.close()\n",
    "\n",
    "# # Concatenate the data into a single array\n",
    "# R = np.concatenate(data)\n",
    "\n",
    "# # Print the shape of the R array\n",
    "# print(\"Shape of R:\", R.shape)\n",
    "\n",
    "# # Print the metadata for each message\n",
    "# for i, grb in enumerate(metadata):\n",
    "#     print(f\"Metadata for message {i+1}:\")\n",
    "#     print(grb)\n",
    "#     print()\n",
    "\n",
    "\n",
    "# # Read the data from the archive\n",
    "# # importer = io.get_method(importer_name, \"importer\")\n",
    "# # R, _, metadata = io.read_timeseries(fns, importer, **importer_kwargs)\n",
    "\n",
    "# # Convert to rain rate\n",
    "# R, metadata = conversion.to_rainrate(R, metadata)\n",
    "\n",
    "# print(R,metadata)\n",
    "# # Upscale data to 2 km to limit memory usage\n",
    "# R, metadata = dimension.aggregate_fields_space(R, metadata, 2000)\n",
    "\n",
    "# # Plot the rainfall field\n",
    "# plot_precip_field(R[-1, :, :], geodata=metadata)\n",
    "# plt.show()\n",
    "\n",
    "# # Log-transform the data to unit of dBR, set the threshold to 0.1 mm/h,\n",
    "# # set the fill value to -15 dBR\n",
    "# R, metadata = transformation.dB_transform(R, metadata, threshold=0.1, zerovalue=-15.0)\n",
    "\n",
    "# # Set missing values with the fill value\n",
    "# R[~np.isfinite(R)] = -15.0\n",
    "\n",
    "# # Nicely print the metadata\n",
    "# pprint(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30322203-cc0c-4367-b83c-ea8896ae8ed1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-mrms]",
   "language": "python",
   "name": "conda-env-.conda-mrms-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
