{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "258cfa16-f76f-452f-97f7-5083ee21343c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pysteps configuration file found at: C:\\Users\\16126\\pysteps\\pystepsrc\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "import os\n",
    "# import gzip\n",
    "import shutil\n",
    "# import cartopy.crs as ccrs\n",
    "# import cartopy.feature\n",
    "# import cartopy\n",
    "# from metpy.plots import USCOUNTIES\n",
    "from datetime import datetime, timedelta\n",
    "# from PIL import Image\n",
    "# import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from pysteps import io, nowcasts, rcparams\n",
    "from pysteps.motion.lucaskanade import dense_lucaskanade\n",
    "# from pysteps.postprocessing.ensemblestats import excprob\n",
    "from pysteps.utils import conversion, dimension, transformation\n",
    "# from pysteps.visualization import plot_precip_field\n",
    "# import matplotlib.colors as colors\n",
    "import re\n",
    "# import pandas as pd\n",
    "from pysteps.nowcasts import anvil, extrapolation, sprog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef73d95-fdc6-42b3-8447-ece5a5f6454b",
   "metadata": {},
   "source": [
    "## Custom import functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cd49c6f-744c-43a3-949e-5ce7b3383e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_mrms_dbz(filename, extent=None, window_size=1, **kwargs):\n",
    "    import pygrib \n",
    "    import pyproj\n",
    "    from functools import partial\n",
    "    from pysteps.utils import aggregate_fields\n",
    "    from pysteps.io.importers import _get_grib_projection, _get_threshold_value\n",
    "    \"\"\"\n",
    "    Importer for NSSL's Multi-Radar/Multi-Sensor System\n",
    "    ([MRMS](https://www.nssl.noaa.gov/projects/mrms/)) radar reflectivity product\n",
    "    (grib format).\n",
    "    Reflectivity values are expressed in dBZ and need to be converted to a rain rate in\n",
    "    mm/h. The dimensions of the data\n",
    "    array are [latitude, longitude]. The first grid point (0,0) corresponds to\n",
    "    the upper left corner of the domain, while (last i, last j) denote the\n",
    "    lower right corner.\n",
    "    Due to the large size of the dataset (3500 x 7000), a float32 type is used\n",
    "    by default to reduce the memory footprint. However, be aware that when this\n",
    "    array is passed to a pystep function, it may be converted to double\n",
    "    precision, doubling the memory footprint.\n",
    "    To change the precision of the data, use the ``dtype`` keyword.\n",
    "    Also, by default, the original data is downscaled by 4\n",
    "    (resulting in a ~4 km grid spacing).\n",
    "    In case that the original grid spacing is needed, use ``window_size=1``.\n",
    "    But be aware that a single composite in double precipitation will\n",
    "    require 186 Mb of memory.\n",
    "    Finally, if desired, the data can be extracted over a\n",
    "    sub region of the full domain using the `extent` keyword.\n",
    "    By default, the entire domain is returned.\n",
    "    Notes\n",
    "    -----\n",
    "    We replace any reflectivity values less than -35 with np.nan.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    filename: str\n",
    "        Name of the file to import.\n",
    "    extent: None or array-like\n",
    "        Longitude and latitude range (in degrees) of the data to be retrieved.\n",
    "        (min_lon, max_lon, min_lat, max_lat).\n",
    "        By default (None), the entire domain is retrieved.\n",
    "        The extent can be in any form that can be converted to a flat array\n",
    "        of 4 elements array (e.g., lists or tuples).\n",
    "    window_size: array_like or int\n",
    "        Array containing down-sampling integer factor along each axis.\n",
    "        If an integer value is given, the same block shape is used for all the\n",
    "        image dimensions.\n",
    "        Default: window_size=4.\n",
    "    {extra_kwargs_doc}\n",
    "    Returns\n",
    "    -------\n",
    "    reflectivity: 2D array, float32\n",
    "        Reflectivity field in dBZ. The dimensions are [latitude, longitude].\n",
    "        The first grid point (0,0) corresponds to the upper left corner of the\n",
    "        domain, while (last i, last j) denote the lower right corner.\n",
    "    quality: None\n",
    "        Not implement.\n",
    "    metadata: dict\n",
    "        Associated metadata (pixel sizes, map projections, etc.).\n",
    "    \"\"\"\n",
    "\n",
    "    del kwargs\n",
    "\n",
    "    try:\n",
    "        grib_file = pygrib.open(filename)\n",
    "    except OSError:\n",
    "        raise OSError(f\"Error opening NCEP's MRMS file. \" f\"File Not Found: {filename}\")\n",
    "\n",
    "    if isinstance(window_size, int):\n",
    "        window_size = (window_size, window_size)\n",
    "\n",
    "    if extent is not None:\n",
    "        extent = np.asarray(extent)\n",
    "        if (extent.ndim != 1) or (extent.size != 4):\n",
    "            raise ValueError(\n",
    "                \"The extent must be None or a flat array with 4 elements.\\n\"\n",
    "                f\"Received: extent.shape = {str(extent.shape)}\"\n",
    "            )\n",
    "\n",
    "    # The MRMS grib file contain one message with the precipitation intensity\n",
    "    grib_file.rewind()\n",
    "    grib_msg = grib_file.read(1)[0]  # Read the only message\n",
    "\n",
    "    # -------------------------\n",
    "    # Read the grid information\n",
    "\n",
    "    lr_lon = grib_msg[\"longitudeOfLastGridPointInDegrees\"]\n",
    "    lr_lat = grib_msg[\"latitudeOfLastGridPointInDegrees\"]\n",
    "\n",
    "    ul_lon = grib_msg[\"longitudeOfFirstGridPointInDegrees\"]\n",
    "    ul_lat = grib_msg[\"latitudeOfFirstGridPointInDegrees\"]\n",
    "\n",
    "    # Ni - Number of points along a latitude circle (west-east)\n",
    "    # Nj - Number of points along a longitude meridian (south-north)\n",
    "    # The lat/lon grid has a 0.01 degrees spacing.\n",
    "    lats = np.linspace(ul_lat, lr_lat, grib_msg[\"Nj\"])\n",
    "    lons = np.linspace(ul_lon, lr_lon, grib_msg[\"Ni\"])\n",
    "\n",
    "    reflectivity = grib_msg.values\n",
    "\n",
    "    # Filter out noise\n",
    "    no_data_mask = reflectivity <= -999.0 #-100\n",
    "    #reflectivity[reflectivity <= -35] = np.nan\n",
    "\n",
    "\n",
    "    # Create a function with default arguments for aggregate_fields\n",
    "    block_reduce = partial(aggregate_fields, method=\"mean\", trim=True)\n",
    "\n",
    "    if window_size != (1, 1):\n",
    "        # Downscale data\n",
    "        lats = block_reduce(lats, window_size[0])\n",
    "        lons = block_reduce(lons, window_size[1])\n",
    "\n",
    "        # Update the limits\n",
    "        ul_lat, lr_lat = lats[0], lats[-1]  # Lat from North to south!\n",
    "        ul_lon, lr_lon = lons[0], lons[-1]\n",
    "\n",
    "        reflectivity[no_data_mask] = 0  # block_reduce does not handle nan values\n",
    "        reflectivity = block_reduce(reflectivity, window_size, axis=(0, 1))\n",
    "\n",
    "        # Consider that if a single invalid observation is located in the block,\n",
    "        # then mark that value as invalid.\n",
    "        no_data_mask = block_reduce(\n",
    "            no_data_mask.astype(\"int\"), window_size, axis=(0, 1)\n",
    "        ).astype(bool)\n",
    "\n",
    "    lons, lats = np.meshgrid(lons, lats)\n",
    "    reflectivity[no_data_mask] = np.nan\n",
    "\n",
    "    if extent is not None:\n",
    "        # clip domain\n",
    "        ul_lon, lr_lon = _check_coords_range(\n",
    "            (extent[0], extent[1]), \"longitude\", (ul_lon, lr_lon)\n",
    "        )\n",
    "\n",
    "        lr_lat, ul_lat = _check_coords_range(\n",
    "            (extent[2], extent[3]), \"latitude\", (ul_lat, lr_lat)\n",
    "        )\n",
    "\n",
    "        mask_lat = (lats >= lr_lat) & (lats <= ul_lat)\n",
    "        mask_lon = (lons >= ul_lon) & (lons <= lr_lon)\n",
    "\n",
    "        nlats = np.count_nonzero(mask_lat[:, 0])\n",
    "        nlons = np.count_nonzero(mask_lon[0, :])\n",
    "\n",
    "        reflectivity = reflectivity[mask_lon & mask_lat].reshape(nlats, nlons)\n",
    "\n",
    "    proj_params = _get_grib_projection(grib_msg)\n",
    "    pr = pyproj.Proj(proj_params)\n",
    "    proj_def = \" \".join([f\"+{key}={value} \" for key, value in proj_params.items()])\n",
    "\n",
    "    xsize = grib_msg[\"iDirectionIncrementInDegrees\"] * window_size[0]\n",
    "    ysize = grib_msg[\"jDirectionIncrementInDegrees\"] * window_size[1]\n",
    "\n",
    "    x1, y1 = pr(ul_lon, lr_lat)\n",
    "    x2, y2 = pr(lr_lon, ul_lat)\n",
    "\n",
    "    metadata = dict(\n",
    "        institution=\"NOAA National Severe Storms Laboratory\",\n",
    "        xpixelsize=xsize,\n",
    "        ypixelsize=ysize,\n",
    "        unit=\"dBZ\",\n",
    "        accutime=2.0,\n",
    "        transform=\"dB\",\n",
    "        zerovalue=-999.0,\n",
    "        projection=proj_def.strip(),\n",
    "        yorigin=\"upper\",\n",
    "        threshold=_get_threshold_value(reflectivity),\n",
    "        x1=x1 - xsize / 2,\n",
    "        x2=x2 + xsize / 2,\n",
    "        y1=y1 - ysize / 2,\n",
    "        y2=y2 + ysize / 2,\n",
    "        cartesian_unit=\"degrees\",\n",
    "        zr_a = 316.0,\n",
    "        zr_b = 1.5\n",
    "    )\n",
    "\n",
    "    return reflectivity, metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9ff8eae-fd55-4f12-8ca1-4213762dc711",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_radar_timeseries(filepath,start_date_str,num_previous_files):\n",
    "    from glob import glob\n",
    "    \"\"\"\n",
    "    Read a time series of input files using the import_mrms_dbz function \n",
    "    and stack them into a 3d array of\n",
    "    shape (num_timesteps, height, width).\n",
    "    Parameters\n",
    "    ----------\n",
    "    filepath: string\n",
    "        Folder path where radar files lives. \n",
    "    start_date_str: string\n",
    "        A date string of the most recent radar file to open (i.e. %Y%m%d-%H%M%S)\n",
    "    num_previous_files: int\n",
    "        Number of previous radar files to ingest.\n",
    "    Returns\n",
    "    -------\n",
    "    out: tuple\n",
    "        A three-element tuple containing the read data and quality rasters and\n",
    "        associated metadata. If an input file name is None, the corresponding\n",
    "        precipitation and quality fields are filled with nan values. If all\n",
    "        input file names are None or if the length of the file name list is\n",
    "        zero, a three-element tuple containing None values is returned.\n",
    "    \"\"\"\n",
    "\n",
    "    reflectivity = []\n",
    "    timestamps = []\n",
    "    \n",
    "    all_files = glob(os.path.join(filepath,'*.grib2'))\n",
    "    if len(all_files)==0:\n",
    "        raise OSError(f\"Error. Not able to find grib2 files in \" f\": {filepath}\")\n",
    "\n",
    "\n",
    "    files_sorted = sorted(all_files)\n",
    "    datelist = [re.search(r\"(\\d{8}-\\d{6})\", i).group() for i in files_sorted]\n",
    "\n",
    "    ind = np.where(np.array(datelist)==start_date_str)[0]\n",
    "    if len(ind)==0:\n",
    "        raise OSError(f\"Error finding matching grib2 file. No match for date: \" f\"{start_date_str}\")\n",
    "\n",
    "    files_keep = files_sorted[ind[0]-num_previous_files:ind[0]+1]\n",
    "    \n",
    "    for i in files_keep:\n",
    "        radar_, metadata = import_mrms_dbz(i)\n",
    "        reflectivity.append(radar_)\n",
    "        timestamps.append(datetime.strptime(re.search(r\"(\\d{8}-\\d{6})\", i).group(), \"%Y%m%d-%H%M%S\")) # Get datetime from filename\n",
    "    \n",
    "\n",
    "    # Idk what this next line does, but it's in the pysteps code: https://github.com/pySTEPS/pysteps/blob/master/pysteps/io/readers.py#L77\n",
    "    reflectivity = np.concatenate([radar_[None, :, :] for radar_ in reflectivity])\n",
    "    metadata[\"timestamps\"] = np.array(timestamps)\n",
    "\n",
    "    return reflectivity, metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add3d636-6618-4430-9acd-e73257899ce5",
   "metadata": {},
   "source": [
    "## Set File Path, Nowcast Parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4661b2b2-4f92-468d-902c-f349459ae47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set MRMS file path\n",
    "filepath = r\"C:\\Users\\16126\\pysteps_data\\mrms_reflectivity\\2023\\06\\15\"\n",
    "# Set the number of MRMS files, forecast timesteps and precip threshold to use in nowcast\n",
    "num_previous_files = 4\n",
    "n_leadtimes = 7\n",
    "precip_thr = -150\n",
    "number_cores = 2 #set to number of cores to use for calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db44089-a206-4c3b-be1b-3683f4c41f6b",
   "metadata": {},
   "source": [
    "## Load in MRMS Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4517c163-7013-43ae-afd5-8c137f9efc99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRMS_ReflectivityAtLowestAltitude_00.50_20230615-205441.grib2\n"
     ]
    }
   ],
   "source": [
    "# Get a list of all files in the input directory\n",
    "files = os.listdir(filepath)\n",
    "files_sorted = sorted(files, reverse=True)\n",
    "print(files_sorted[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6ee06da-b808-48d4-8d3c-7eb99a138ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the most recent MRMS file name from list of files\n",
    "filename = files_sorted[0]\n",
    "\n",
    "# Extract year, month, day, hour, minute, and seconds\n",
    "year = filename[40:44]\n",
    "month = filename[44:46]\n",
    "day = filename[46:48]\n",
    "hour = filename[49:51]\n",
    "minute = filename[51:53]\n",
    "second = filename[53:55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12cc9271-5a00-4134-b55b-eb0729b5577f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 3500, 7000)\n",
      "{'institution': 'NOAA National Severe Storms Laboratory', 'xpixelsize': 0.01, 'ypixelsize': 0.01, 'unit': 'dBZ', 'accutime': 2.0, 'transform': 'dB', 'zerovalue': -999.0, 'projection': '+proj=longlat  +ellps=IAU76', 'yorigin': 'upper', 'threshold': -6.0, 'x1': -129.99999999999997, 'x2': -60.00000199999991, 'y1': 20.000001, 'y2': 55.00000000000001, 'cartesian_unit': 'degrees', 'zr_a': 316.0, 'zr_b': 1.5, 'timestamps': array([datetime.datetime(2023, 6, 15, 20, 22, 42),\n",
      "       datetime.datetime(2023, 6, 15, 20, 30, 41),\n",
      "       datetime.datetime(2023, 6, 15, 20, 38, 42),\n",
      "       datetime.datetime(2023, 6, 15, 20, 46, 40),\n",
      "       datetime.datetime(2023, 6, 15, 20, 54, 41)], dtype=object)}\n"
     ]
    }
   ],
   "source": [
    "start_date_str = f\"{year}{month}{day}-{hour}{minute}{second}\"\n",
    "\n",
    "# Change this to be DBZ, metadata = .... then convert DBZ to R\n",
    "R, metadata = read_radar_timeseries(filepath, start_date_str, num_previous_files)\n",
    "print(R.shape)\n",
    "print(metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a20f9f8-527c-40ed-9463-4d988c29f947",
   "metadata": {},
   "source": [
    "## Converstions / Upscaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "041e4779-0974-47cd-a5eb-92e98e75fa34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 3500, 7000)\n",
      "(5, 875, 1750)\n"
     ]
    }
   ],
   "source": [
    "# Convert dbZ to rain rate (similar to MCH example)\n",
    "RR, metadata_RR = conversion.to_rainrate(R, metadata)\n",
    "print(RR.shape)\n",
    "\n",
    "# Upscale data to 4 km to limit memory usage\n",
    "R_down, metadata_down = dimension.aggregate_fields_space(RR, metadata_RR, 0.04)\n",
    "print(R_down.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b81c48b1-7b99-4ac3-944e-3e8e2f4e1a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R_down, metadata_down\n",
    "R = R_down\n",
    "metadata = metadata_down\n",
    "\n",
    "R = conversion.to_reflectivity(R,metadata)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd5920d-21c1-409c-84d9-1b92257aa224",
   "metadata": {},
   "source": [
    "## <font color='Black'>Calculate Motion</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "709a947e-9d44-4037-ac57-ebe8d6645437",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pysteps import motion\n",
    "DBR, metadata_DBR = transformation.dB_transform(R_down, metadata_down, threshold=0.1, zerovalue=-15)\n",
    "V = dense_lucaskanade(DBR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cb0c98-ceb3-49ef-ac2f-099e8e67bac5",
   "metadata": {},
   "source": [
    "## <font color='Orange'>ANVIL</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "764df7fc-741d-479c-a0e5-0850d1c1c305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ANVIL nowcast\n",
      "-----------------------\n",
      "\n",
      "Inputs\n",
      "------\n",
      "input dimensions: 875x1750\n",
      "\n",
      "Methods\n",
      "-------\n",
      "extrapolation:   semilagrangian\n",
      "FFT:             numpy\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "number of time steps:        7\n",
      "parallel threads:            2\n",
      "number of cascade levels:    8\n",
      "order of the ARI(p,1) model: 2\n",
      "ARI(p,1) window radius:      25\n",
      "R(VIL) window radius:        3\n",
      "Starting nowcast computation.\n",
      "Computing nowcast for time step 1... done.\n",
      "Computing nowcast for time step 2... done.\n",
      "Computing nowcast for time step 3... done.\n",
      "Computing nowcast for time step 4... done.\n",
      "Computing nowcast for time step 5... done.\n",
      "Computing nowcast for time step 6... done.\n",
      "Computing nowcast for time step 7... done.\n",
      "38.01028609275818\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "forecast_anvil = anvil.forecast(\n",
    "    R_down[-4:, :, :],    \n",
    "    V,\n",
    "    n_leadtimes,\n",
    "    n_cascade_levels=8,\n",
    "    # precip_thr=precip_thr,\n",
    "    extrap_method='semilagrangian',\n",
    "    # probmatching_method=\"cdf\",\n",
    "    ar_order = 2,\n",
    "    ar_window_radius=25,\n",
    "    num_workers = number_cores\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "# num_prev_files = num_previous_files\n",
    "# method = 'ANVIL'\n",
    "# df = pd.read_csv(r\"G:\\My Drive\\PowPow\\Resort Graphs\\forecast_radar\\calc_duration.csv\")\n",
    "# # Create a new row with the variables as columns\n",
    "# new_row = {\"method\": method,\"num_prev_files\": num_prev_files,\"n_ens_members\": n_ens_members,\"n_leadtimes\": n_leadtimes,\"seed\": seed,\"execution_time\": execution_time,}\n",
    "# # Convert the new row to a DataFrame\n",
    "# new_row_df = pd.DataFrame([new_row])\n",
    "# # Concatenate the original DataFrame with the new row DataFrame\n",
    "# df = pd.concat([df, new_row_df], ignore_index=True)\n",
    "# # Save the modified DataFrame to a new CSV file\n",
    "# df.to_csv(r\"G:\\My Drive\\PowPow\\Resort Graphs\\forecast_radar\\calc_duration.csv\", index=False)\n",
    "\n",
    "print(execution_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5cec96-5676-4362-8acb-41ed0dcae21a",
   "metadata": {},
   "source": [
    "## Convert ANVIL to dBZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f96cfc9-157a-4c21-adaf-c4d1c4de7e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_anvil_dbz, metadata_forecast = conversion.to_reflectivity(forecast_anvil,metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5fd5ed9b-4423-42c6-baac-5faed754a1ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[datetime.datetime(2023, 6, 15, 20, 22, 42)\n",
      " datetime.datetime(2023, 6, 15, 20, 30, 41)\n",
      " datetime.datetime(2023, 6, 15, 20, 38, 42)\n",
      " datetime.datetime(2023, 6, 15, 20, 46, 40)\n",
      " datetime.datetime(2023, 6, 15, 20, 54, 41)]\n",
      "2023-06-15 20:54:41\n",
      "[datetime.datetime(2023, 6, 15, 21, 2, 41), datetime.datetime(2023, 6, 15, 21, 10, 41), datetime.datetime(2023, 6, 15, 21, 18, 41), datetime.datetime(2023, 6, 15, 21, 26, 41), datetime.datetime(2023, 6, 15, 21, 34, 41), datetime.datetime(2023, 6, 15, 21, 42, 41), datetime.datetime(2023, 6, 15, 21, 50, 41)]\n"
     ]
    }
   ],
   "source": [
    "print(metadata_forecast['timestamps'])\n",
    "\n",
    "cur_time = np.max(metadata['timestamps'])\n",
    "print(cur_time)\n",
    "new_timestamps = []\n",
    "for i in range(forecast_anvil_dbz.shape[0]):\n",
    "    new_timestamps.append(cur_time+timedelta(minutes=8))\n",
    "    cur_time+=timedelta(minutes=8)\n",
    "    \n",
    "print(new_timestamps)\n",
    "\n",
    "metadata_forecast['timestamps'] = new_timestamps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b20b616-8c35-46d4-aa69-8e46617148ea",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b23dfbc2-caf5-413a-af49-d611fc9ef6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(forecast_anvil_dbz.shape)\n",
    "# print(metadata_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce1d5951-d47d-4aa6-89d1-c6e12f0ef1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(forecast_anvil_dbz[i,:,:][np.newaxis,:,:].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c1d0190-da8b-4e51-9ea3-b56ebd5bb03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pysteps.io.exporters import initialize_forecast_exporter_netcdf,close_forecast_files,export_forecast_dataset\n",
    "\n",
    "# metadata_forecast_single = metadata_forecast.copy()\n",
    "# for i in range(forecast_anvil_dbz.shape[0]):\n",
    "#     metadata_forecast_single['timestamps'] = [metadata_forecast['timestamps'][i]]\n",
    "#     print(metadata_forecast_single['timestamps'])\n",
    "    \n",
    "#     tstamp = datetime.strftime(metadata_forecast['timestamps'][i],'%Y%m%d%H%M')\n",
    "\n",
    "#     exporter = initialize_forecast_exporter_netcdf(r'.','mrms_nowcast_dbz5_'+tstamp, metadata_forecast['timestamps'][i], 8, \n",
    "#                                                    1, (875, 1750), metadata_forecast_single, 1,'member')\n",
    "\n",
    "#     export_forecast_dataset(forecast_anvil_dbz[i,:,:][np.newaxis,:,:],exporter)\n",
    "#     close_forecast_files(exporter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6796bb05-f129-4def-ad75-156378ee8f3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'institution': 'NOAA National Severe Storms Laboratory',\n",
       " 'xpixelsize': 0.04,\n",
       " 'ypixelsize': 0.04,\n",
       " 'unit': 'dBZ',\n",
       " 'accutime': 2.0,\n",
       " 'transform': 'dB',\n",
       " 'zerovalue': -10.999999999999996,\n",
       " 'projection': '+proj=longlat  +ellps=IAU76',\n",
       " 'yorigin': 'upper',\n",
       " 'threshold': -5.999999999999997,\n",
       " 'x1': -129.99999999999997,\n",
       " 'x2': -60.00000199999991,\n",
       " 'y1': 20.000001,\n",
       " 'y2': 55.00000000000001,\n",
       " 'cartesian_unit': 'degrees',\n",
       " 'zr_a': 316.0,\n",
       " 'zr_b': 1.5,\n",
       " 'timestamps': [datetime.datetime(2023, 6, 15, 21, 2, 41),\n",
       "  datetime.datetime(2023, 6, 15, 21, 10, 41),\n",
       "  datetime.datetime(2023, 6, 15, 21, 18, 41),\n",
       "  datetime.datetime(2023, 6, 15, 21, 26, 41),\n",
       "  datetime.datetime(2023, 6, 15, 21, 34, 41),\n",
       "  datetime.datetime(2023, 6, 15, 21, 42, 41),\n",
       "  datetime.datetime(2023, 6, 15, 21, 50, 41)]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d905c02-baf1-4dae-b7ed-b0acedf16e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pysteps.io.exporters import initialize_forecast_exporter_netcdf,close_forecast_files,export_forecast_dataset\n",
    "\n",
    "# # initialize_forecast_exporter_netcdf(outpath =r'.', outfnprefix ='rain_rate', date,timestep = 8, n_timesteps = 7, shape=(875, 1750), metadata=metadata, n_ens_members=28,incremental='timestep')\n",
    "# exporter = initialize_forecast_exporter_netcdf(r'.','mrms_nowcast_dbz', date,8, 7, (875, 1750), metadata_forecast, 28,'member')\n",
    "# print(exporter)\n",
    "\n",
    "# export_forecast_dataset(forecast_anvil_dbz,exporter)\n",
    "# close_forecast_files(exporter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9623207a-1a3d-46d3-b492-143a86c9554a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-mrms]",
   "language": "python",
   "name": "conda-env-.conda-mrms-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
